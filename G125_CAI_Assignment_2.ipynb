{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34abc30f095a43ea8fc0c92dee269025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f15c4b7dd0ec4052bea1422eda75138a",
              "IPY_MODEL_208f2e4527c0482186aefcbf9f714c44",
              "IPY_MODEL_66984cae718441b18146da6347e190ea"
            ],
            "layout": "IPY_MODEL_112d5f67a90240478e5acf4c8a2621b7"
          }
        },
        "f15c4b7dd0ec4052bea1422eda75138a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b1793d158314ee3846d8b10c68135b5",
            "placeholder": "​",
            "style": "IPY_MODEL_54be519411084ceaa5e83d7c5f72b0d7",
            "value": "Filling 21 fixed URLs: "
          }
        },
        "208f2e4527c0482186aefcbf9f714c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911439ec14e344ffae55febcdeab8cd4",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6ccefd6d79143cb8dcc086862e4d7a4",
            "value": 21
          }
        },
        "66984cae718441b18146da6347e190ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_623960de828b4037997dc3a6f919f6b6",
            "placeholder": "​",
            "style": "IPY_MODEL_a64344e12e614ba78b78f1ec6e25a495",
            "value": " 25/? [00:09&lt;00:00,  3.59it/s]"
          }
        },
        "112d5f67a90240478e5acf4c8a2621b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b1793d158314ee3846d8b10c68135b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54be519411084ceaa5e83d7c5f72b0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "911439ec14e344ffae55febcdeab8cd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ccefd6d79143cb8dcc086862e4d7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "623960de828b4037997dc3a6f919f6b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a64344e12e614ba78b78f1ec6e25a495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e64f293914b74d0fa9453b0b792ff1d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c76f1f5e2e29416c9080d85091a8a301",
              "IPY_MODEL_4261572d2e0040cba64660e9d7c3882b",
              "IPY_MODEL_6b62e16de440438d9475980576ffaf6d"
            ],
            "layout": "IPY_MODEL_1cfad5a0712e47fca52a3815c36f0558"
          }
        },
        "c76f1f5e2e29416c9080d85091a8a301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36287fd9ae714cec93d7d055e2ce3e87",
            "placeholder": "​",
            "style": "IPY_MODEL_a1c6a881c9e74bc7a375005cd21d618e",
            "value": "Collecting 300 random URLs: 100%"
          }
        },
        "4261572d2e0040cba64660e9d7c3882b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2d54d1939bf48ac91c359aad0ff46dd",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3884e93e45b49e6ad6649e56b73f624",
            "value": 300
          }
        },
        "6b62e16de440438d9475980576ffaf6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f65959404c42a98f21333855d56381",
            "placeholder": "​",
            "style": "IPY_MODEL_1053525762b040e0b0316eb2c62b38ce",
            "value": " 300/300 [01:38&lt;00:00,  3.49it/s]"
          }
        },
        "1cfad5a0712e47fca52a3815c36f0558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36287fd9ae714cec93d7d055e2ce3e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c6a881c9e74bc7a375005cd21d618e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2d54d1939bf48ac91c359aad0ff46dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3884e93e45b49e6ad6649e56b73f624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78f65959404c42a98f21333855d56381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1053525762b040e0b0316eb2c62b38ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54e8838843e140b39887bb14a733bbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40f4dafb7eb74014bb4531229925357d",
              "IPY_MODEL_a4b9e411aeab403596f785740a41f7e2",
              "IPY_MODEL_4e8bf1a924aa46dcb9403dd8b0159a59"
            ],
            "layout": "IPY_MODEL_d31f907a24414c26866cad1cb39aa13d"
          }
        },
        "40f4dafb7eb74014bb4531229925357d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f34948b881264ec084947b28339d34ac",
            "placeholder": "​",
            "style": "IPY_MODEL_8d540ac114264dc599fb2c9165c958fa",
            "value": "Loading weights: 100%"
          }
        },
        "a4b9e411aeab403596f785740a41f7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52ba86fc7a80400285976856854e0149",
            "max": 291,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2408e152cdd24ff1b1ae67cdd554ee3e",
            "value": 291
          }
        },
        "4e8bf1a924aa46dcb9403dd8b0159a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e655ec11b3342478c8be14b730a94f5",
            "placeholder": "​",
            "style": "IPY_MODEL_bf6ca61d08ef44e182c8e4a9bf176b1c",
            "value": " 291/291 [01:02&lt;00:00, 155.52it/s, Materializing param=model.norm.weight]"
          }
        },
        "d31f907a24414c26866cad1cb39aa13d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f34948b881264ec084947b28339d34ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d540ac114264dc599fb2c9165c958fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52ba86fc7a80400285976856854e0149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2408e152cdd24ff1b1ae67cdd554ee3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e655ec11b3342478c8be14b730a94f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf6ca61d08ef44e182c8e4a9bf176b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b00415230694033a8793313cca9349b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be915bd27fc446d48507d2f3d26c0b57",
              "IPY_MODEL_6400bf4cfb1e405391e819f2c8e97c92",
              "IPY_MODEL_352bbcb9a8a9436ca5870e9bb4319939"
            ],
            "layout": "IPY_MODEL_08dd9c886a4b4205896c7e16889a0d1a"
          }
        },
        "be915bd27fc446d48507d2f3d26c0b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_890bcc9019d24578b3e9a8f24667ce78",
            "placeholder": "​",
            "style": "IPY_MODEL_c344fa80eeda4326b2c7eb92c76e4637",
            "value": "generation_config.json: 100%"
          }
        },
        "6400bf4cfb1e405391e819f2c8e97c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b514cffda96d44a9bde096910db78801",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_050cc7088e18449bae29031ad84660e6",
            "value": 111
          }
        },
        "352bbcb9a8a9436ca5870e9bb4319939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9c882d616bf438aacb3fce7eddf8bbf",
            "placeholder": "​",
            "style": "IPY_MODEL_0142f3df990a4ddc90cdf004cb7aae71",
            "value": " 111/111 [00:00&lt;00:00, 10.4kB/s]"
          }
        },
        "08dd9c886a4b4205896c7e16889a0d1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "890bcc9019d24578b3e9a8f24667ce78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c344fa80eeda4326b2c7eb92c76e4637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b514cffda96d44a9bde096910db78801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "050cc7088e18449bae29031ad84660e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9c882d616bf438aacb3fce7eddf8bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0142f3df990a4ddc90cdf004cb7aae71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "215e0caea56e422db0b46893ffa4663f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7aef0e0436bf4e6fa422a22f64e603dd",
              "IPY_MODEL_72324b180c734bcc8dc1507cb43b0988",
              "IPY_MODEL_eee6d83235c540868705fde7a5a96971"
            ],
            "layout": "IPY_MODEL_7cc71f94fcbc45848c48ab0d4a95f3ef"
          }
        },
        "7aef0e0436bf4e6fa422a22f64e603dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4bcd77f20947a5a767ff24c257601a",
            "placeholder": "​",
            "style": "IPY_MODEL_b1da89cc6c984b79bffc24a92ed20083",
            "value": "Batches: 100%"
          }
        },
        "72324b180c734bcc8dc1507cb43b0988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c996f9d178c46f385b3ba6e1a91c63e",
            "max": 78,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dc253280bf2460abc8bec61e121dd59",
            "value": 78
          }
        },
        "eee6d83235c540868705fde7a5a96971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b01b3b6cb342e6af7f7a973f26aeae",
            "placeholder": "​",
            "style": "IPY_MODEL_ba1988c679d0467dae0aab44ad5a7a32",
            "value": " 78/78 [00:08&lt;00:00,  9.64it/s]"
          }
        },
        "7cc71f94fcbc45848c48ab0d4a95f3ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4bcd77f20947a5a767ff24c257601a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1da89cc6c984b79bffc24a92ed20083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c996f9d178c46f385b3ba6e1a91c63e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dc253280bf2460abc8bec61e121dd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02b01b3b6cb342e6af7f7a973f26aeae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba1988c679d0467dae0aab44ad5a7a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conversational AI - Assignment 2\n"
      ],
      "metadata": {
        "id": "hqv0g1TcVNtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group ID: 125\n",
        "### Group Members Name with Student ID:\n",
        "\n",
        "| BITS ID     | Name                         | Contribution |\n",
        "|-------------|----------------------------- |--------------|\n",
        "| **2024AA05346** | **Tamilselvan S**              |     100%     |\n",
        "| **2024AB05320** | **Mathi Yuvarajan T K**            |     100%     |\n",
        "| **2024aa05279** | **Bhartendu Kumar**                 |     100%     |\n",
        "| **2024aa05198** | **Rakesh Jha**          |     100%     |\n",
        "| **2024aa05957** | **Shripad Prakash Kelapure**                   |     100%     |\n"
      ],
      "metadata": {
        "id": "VFvEv38UVQxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective :\n",
        "\n",
        "The objective of this assignment is to design and implement a **Hybrid Retrieval-Augmented Generation (RAG) system** that combines **dense vector-based retrieval** and **sparse keyword-based retrieval (BM25)** using **Reciprocal Rank Fusion (RRF)**.\n",
        "\n",
        "The system should answer user queries based on a corpus of **500 Wikipedia articles** and be evaluated using an **automated evaluation framework** with **100 generated questions**."
      ],
      "metadata": {
        "id": "ObnZJ0UJtfMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installation & Import"
      ],
      "metadata": {
        "id": "AJTO1tSDvoQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wikipedia-api transformers rank_bm25 sentence-transformers faiss-cpu nltk fastapi uvicorn nest-asyncio pyngrok\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "import uuid\n",
        "import collections\n",
        "import urllib.parse\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import torch\n",
        "import faiss\n",
        "import wikipediaapi\n",
        "import nltk\n",
        "import ipywidgets as widgets\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "import threading\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from pyngrok import ngrok\n",
        "from tqdm.notebook import tqdm\n",
        "from nltk.tokenize import word_tokenize\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from rank_bm25 import BM25Okapi\n",
        "from IPython.display import display, HTML\n",
        "from IPython.display import display, HTML\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4nnoNXwv0CBb",
        "outputId": "d86ce29e-ccf7-4c2f-94bb-5b54e200dc8f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bitsandbytes\n",
        "from transformers import AutoModelForCausalLM\n"
      ],
      "metadata": {
        "id": "wWVwzQbTXILv"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Requirements\n",
        "\n",
        "Each indexing run must use a total of **500 Wikipedia articles**, divided as follows:\n",
        "\n",
        "#### Fixed URL Set (200 URLs)\n",
        "- Each group first sample a **unique set of 200 Wikipedia URLs**.\n",
        "- Each Wikipedia page contain **at least 200 words**.\n",
        "- URLs covers **diverse topics**.\n",
        "- These URLs are stored in a file named `fixed_urls.json`.\n",
        "- The fixed URL set **remain constant across all indexing runs**.\n",
        "- No two groups should share the same fixed URL set.\n",
        "\n",
        "#### Random URL Set (300 URLs)\n",
        "- For each indexing run, **300 additional Wikipedia URLs** are be randomly sampled.\n",
        "- Each page contain **at least 200 words**.\n",
        "- These URLs are **different for every rebuild or re-indexing process**.\n",
        "\n",
        "#### Total Corpus\n",
        "- Total number of articles per run:  \n",
        "  **200 fixed + 300 random = 500 Wikipedia articles**\n"
      ],
      "metadata": {
        "id": "JzEMxcT8vFsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Dataset Generation\n",
        "\n",
        "This task involves creating a dataset by collecting Wikipedia URLs based on the given categories. All URLs are stored in the **CAI_G125** folder under two files:\n",
        "\n",
        "**fixed_urls.json** – contains 200 predefined Wikipedia URLs\n",
        "\n",
        "**random_urls.json** – contains 300 randomly selected Wikipedia URLs\n",
        "\n",
        "In total, the dataset includes 500 Wikipedia URLs organized for further use."
      ],
      "metadata": {
        "id": "oqWeze1s0Ph_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Config\n",
        "\n",
        "FIXED_URL_COUNT  = 200\n",
        "RANDOM_URL_COUNT = 300\n",
        "\n",
        "MIN_WORDS_FIXED  = 200      # strict for fixed set\n",
        "MIN_WORDS_RANDOM = 150      # relaxed for random sampling\n",
        "\n",
        "CATEGORIES = [\n",
        "    \"Artificial intelligence\",\n",
        "    \"Computer science\",\n",
        "    \"Machine learning\",\n",
        "    \"Physics\",\n",
        "    \"Biology\",\n",
        "    \"Chemistry\",\n",
        "    \"Mathematics\",\n",
        "    \"Engineering\",\n",
        "    \"Technology\",\n",
        "    \"Software engineering\",\n",
        "    \"Data science\",\n",
        "    \"Neuroscience\",\n",
        "    \"Computer vision\",\n",
        "    \"Natural language processing\",\n",
        "    \"Artificial neural networks\",\n",
        "    \"Information theory\",\n",
        "    \"Control theory\"\n",
        "]\n",
        "\n",
        "DATA_DIR = \"/CAI_G125\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "OUTPUT_FIXED  = f\"{DATA_DIR}/fixed_urls.json\"\n",
        "OUTPUT_RANDOM = f\"{DATA_DIR}/random_urls.json\"\n",
        "\n",
        "\n",
        "wiki = wikipediaapi.Wikipedia(\n",
        "    language=\"en\",\n",
        "    user_agent=\"HybridRAGAssignment/1.0 (GoogleColab; contact: colab-user@example.com)\" # Updated user agent\n",
        ")\n",
        "\n",
        "# SAFE PAGE LOADER (ARTICLES ONLY)\n",
        "\n",
        "def safe_page(title):\n",
        "    try:\n",
        "        page = wiki.page(title)\n",
        "        if not page.exists():\n",
        "            return None\n",
        "        if not page.text or len(page.text.strip()) == 0:\n",
        "            return None\n",
        "\n",
        "        if page.summary.startswith(\"Disambiguation page\"):\n",
        "            return None\n",
        "        return page\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# FIXED URL GENERATION (CATEGORY + RANDOM FALLBACK)\n",
        "\n",
        "\n",
        "def collect_fixed_urls():\n",
        "    urls = set()\n",
        "    print(\"Collecting FIXED URLs (phase 1: category quotas)...\")\n",
        "\n",
        "    # Phase 1: Category quota sampling (try to get per_category articles)\n",
        "    per_category = FIXED_URL_COUNT // len(CATEGORIES)\n",
        "    for category in CATEGORIES:\n",
        "        if len(urls) >= FIXED_URL_COUNT: break\n",
        "        try:\n",
        "            cat_page = wiki.page(f\"Category:{category}\")\n",
        "            if not cat_page.exists(): continue\n",
        "\n",
        "            collected_in_category = 0\n",
        "            # Get members and shuffle them, and iterate to find enough\n",
        "            members_titles = [m_title for m_title, m_member in cat_page.categorymembers.items() if m_member.ns == wikipediaapi.Namespace.MAIN]\n",
        "            random.shuffle(members_titles)\n",
        "\n",
        "            for title in members_titles:\n",
        "                if len(urls) >= FIXED_URL_COUNT: break\n",
        "                if collected_in_category >= per_category: break # Stop when quota met for this category\n",
        "\n",
        "                page = safe_page(title)\n",
        "                if not page: continue\n",
        "\n",
        "                if len(page.text.split()) >= MIN_WORDS_FIXED:\n",
        "                    urls.add(page.fullurl)\n",
        "                    collected_in_category += 1\n",
        "                time.sleep(0.01) # Small delay\n",
        "\n",
        "        except Exception:\n",
        "            # print(f\"Error in Phase 1 for category {category}\") # Debug\n",
        "            continue\n",
        "\n",
        "    print(f\"Phase 1 collected {len(urls)} URLs\")\n",
        "\n",
        "    # Phase 2: Fill remaining with a broader search from all categories, more aggressively\n",
        "    if len(urls) < FIXED_URL_COUNT:\n",
        "        needed = FIXED_URL_COUNT - len(urls)\n",
        "        print(f\"Phase 2 filling remaining {needed} URLs using category seeding more broadly...\")\n",
        "\n",
        "        all_category_member_titles = []\n",
        "        shuffled_categories = list(CATEGORIES)\n",
        "        random.shuffle(shuffled_categories)\n",
        "\n",
        "        for category in shuffled_categories:\n",
        "            try:\n",
        "                cat_page = wiki.page(f\"Category:{category}\")\n",
        "                if cat_page.exists():\n",
        "                    all_category_member_titles.extend([m_title for m_title, m_member in cat_page.categorymembers.items() if m_member.ns == wikipediaapi.Namespace.MAIN])\n",
        "            except Exception:\n",
        "                # print(f\"Error collecting all titles from category {category} in Phase 2\") # Debug\n",
        "                continue\n",
        "            time.sleep(0.1) # Delay between categories\n",
        "\n",
        "        random.shuffle(all_category_member_titles)\n",
        "\n",
        "        attempts_to_fill_fixed = 0\n",
        "        max_attempts_fill_fixed = needed * 10 # Try up to 10 times per needed URL\n",
        "\n",
        "        with tqdm(total=needed, desc=f\"Filling {needed} fixed URLs\") as pbar:\n",
        "            for title in all_category_member_titles:\n",
        "                if len(urls) >= FIXED_URL_COUNT or attempts_to_fill_fixed >= max_attempts_fill_fixed:\n",
        "                    break\n",
        "\n",
        "                if title in urls: continue # Skip if already collected\n",
        "\n",
        "                page = safe_page(title)\n",
        "                if not page: continue\n",
        "\n",
        "                if len(page.text.split()) >= MIN_WORDS_RANDOM: # Use relaxed threshold for fallback\n",
        "                    urls.add(page.fullurl)\n",
        "                    pbar.update(1)\n",
        "\n",
        "                attempts_to_fill_fixed += 1\n",
        "                time.sleep(0.01) # Small delay for page fetch\n",
        "\n",
        "            pbar.close()\n",
        "\n",
        "\n",
        "    urls_list = list(urls)\n",
        "    random.shuffle(urls_list)\n",
        "    urls_list = urls_list[:FIXED_URL_COUNT] # Truncate to exact count\n",
        "\n",
        "    print(f\"Final fixed URL count: {len(urls_list)}\")\n",
        "    return urls_list\n",
        "\n",
        "# RANDOM URL GENERATION (PER RUN)\n",
        "\n",
        "def sample_random_urls(n):\n",
        "    urls = set()\n",
        "    potential_titles_pool = set()\n",
        "    max_category_members_to_scan = 50000 # Increased to ensure a large enough pool\n",
        "\n",
        "    print(\"🎲 Collecting RANDOM URLs (building a pool from categories)...\")\n",
        "\n",
        "    shuffled_categories = list(CATEGORIES)\n",
        "    random.shuffle(shuffled_categories)\n",
        "\n",
        "    for category_name in shuffled_categories:\n",
        "        if len(potential_titles_pool) >= max_category_members_to_scan: # Cap pool size\n",
        "            print(f\"  Pool of potential titles reached {max_category_members_to_scan}. Stopping category scans.\")\n",
        "            break\n",
        "\n",
        "        try_count = 0\n",
        "        max_category_tries = 5 # Increased retry attempts for categories\n",
        "        while try_count < max_category_tries:\n",
        "            try:\n",
        "                cat_page = wiki.page(f\"Category:{category_name}\")\n",
        "                if cat_page.exists():\n",
        "                    for title, member in cat_page.categorymembers.items():\n",
        "                        if member.ns == wikipediaapi.Namespace.MAIN: # Only main articles\n",
        "                            potential_titles_pool.add(title)\n",
        "                break # Break out of while loop if successful\n",
        "            except Exception as e:\n",
        "                try_count += 1\n",
        "                # print(f\"  Error fetching members for Category:{category_name} (Attempt {try_count}/{max_category_tries}): {e}\") # Debug only\n",
        "                time.sleep(try_count * 1.0) # More aggressive exponential backoff for category errors\n",
        "                if try_count == max_category_tries:\n",
        "                    print(f\"  Failed to fetch members for Category:{category_name} after {max_category_tries} attempts. Skipping.\")\n",
        "                    break # Skip category if max tries reached\n",
        "\n",
        "    print(f\"  Initial pool of potential titles: {len(potential_titles_pool)} titles.\")\n",
        "\n",
        "    if not potential_titles_pool:\n",
        "        print(\"  Warning: No potential titles collected from categories. Cannot sample random URLs.\")\n",
        "        return []\n",
        "\n",
        "    # Now, sample from this pool until we get 'n' valid URLs or exhaust attempts\n",
        "    max_sampling_attempts = n * 50 # Allow 50 attempts per target URL\n",
        "    current_titles_to_sample_from = list(potential_titles_pool) # Copy for sampling\n",
        "    random.shuffle(current_titles_to_sample_from)\n",
        "    title_idx = 0\n",
        "\n",
        "    print(f\"🎲 Sampling {n} random URLs from pool...\")\n",
        "    with tqdm(total=n, desc=f\"Collecting {n} random URLs\") as pbar:\n",
        "        attempts_made = 0\n",
        "        while len(urls) < n and attempts_made < max_sampling_attempts:\n",
        "            if title_idx >= len(current_titles_to_sample_from):\n",
        "                # Reshuffle and reset index if we exhausted the current sampling list\n",
        "                if not potential_titles_pool: # Check if original pool is empty\n",
        "                    print(\"  Warning: Potential titles pool became empty during sampling.\")\n",
        "                    break\n",
        "                current_titles_to_sample_from = list(potential_titles_pool) # Re-populate from original pool\n",
        "                random.shuffle(current_titles_to_sample_from)\n",
        "                title_idx = 0\n",
        "                if not current_titles_to_sample_from:\n",
        "                    print(\"  Warning: No more unique titles left in the pool to sample from after reshuffling.\")\n",
        "                    break\n",
        "\n",
        "            title = current_titles_to_sample_from[title_idx]\n",
        "            title_idx += 1\n",
        "            attempts_made += 1\n",
        "\n",
        "            page = safe_page(title)\n",
        "            if page and len(page.text.split()) >= MIN_WORDS_RANDOM: # Apply word count filter\n",
        "                if page.fullurl not in urls: # Only add if unique\n",
        "                    urls.add(page.fullurl)\n",
        "                    pbar.update(1) # Update progress bar\n",
        "\n",
        "            if attempts_made % 10 == 0: # Small delay to be polite to Wikipedia API during sampling\n",
        "                time.sleep(0.05)\n",
        "        pbar.close()\n",
        "\n",
        "    urls_list = list(urls)\n",
        "    random.shuffle(urls_list) # Final shuffle\n",
        "    urls_list = urls_list[:n] # Truncate if we somehow got more than n\n",
        "\n",
        "    print(f\"✅ Collected {len(urls_list)} random URLs.\")\n",
        "    return urls_list\n",
        "\n",
        "\n",
        "# Helper Functons\n",
        "def save_json(data, path):\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(data, f, indent=2)\n",
        "\n",
        "# Main Function\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fixed_urls = collect_fixed_urls()\n",
        "    save_json(fixed_urls, OUTPUT_FIXED)\n",
        "\n",
        "    random_urls = sample_random_urls(RANDOM_URL_COUNT)\n",
        "    save_json(random_urls, OUTPUT_RANDOM)\n",
        "\n",
        "    print(\"DONE\")\n",
        "    print(f\"Fixed URLs:  {len(fixed_urls)} → {OUTPUT_FIXED}\")\n",
        "    print(f\"Random URLs: {len(random_urls)} → {OUTPUT_RANDOM}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "34abc30f095a43ea8fc0c92dee269025",
            "f15c4b7dd0ec4052bea1422eda75138a",
            "208f2e4527c0482186aefcbf9f714c44",
            "66984cae718441b18146da6347e190ea",
            "112d5f67a90240478e5acf4c8a2621b7",
            "9b1793d158314ee3846d8b10c68135b5",
            "54be519411084ceaa5e83d7c5f72b0d7",
            "911439ec14e344ffae55febcdeab8cd4",
            "d6ccefd6d79143cb8dcc086862e4d7a4",
            "623960de828b4037997dc3a6f919f6b6",
            "a64344e12e614ba78b78f1ec6e25a495",
            "e64f293914b74d0fa9453b0b792ff1d0",
            "c76f1f5e2e29416c9080d85091a8a301",
            "4261572d2e0040cba64660e9d7c3882b",
            "6b62e16de440438d9475980576ffaf6d",
            "1cfad5a0712e47fca52a3815c36f0558",
            "36287fd9ae714cec93d7d055e2ce3e87",
            "a1c6a881c9e74bc7a375005cd21d618e",
            "f2d54d1939bf48ac91c359aad0ff46dd",
            "f3884e93e45b49e6ad6649e56b73f624",
            "78f65959404c42a98f21333855d56381",
            "1053525762b040e0b0316eb2c62b38ce"
          ]
        },
        "id": "g-2bERZ80VmB",
        "outputId": "2c9b2090-c7c0-4c24-8777-0d98dbffbce1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting FIXED URLs (phase 1: category quotas)...\n",
            "Phase 1 collected 179 URLs\n",
            "Phase 2 filling remaining 21 URLs using category seeding more broadly...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filling 21 fixed URLs:   0%|          | 0/21 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34abc30f095a43ea8fc0c92dee269025"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final fixed URL count: 200\n",
            "🎲 Collecting RANDOM URLs (building a pool from categories)...\n",
            "  Initial pool of potential titles: 1868 titles.\n",
            "🎲 Sampling 300 random URLs from pool...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Collecting 300 random URLs:   0%|          | 0/300 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e64f293914b74d0fa9453b0b792ff1d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Collected 300 random URLs.\n",
            "DONE\n",
            "Fixed URLs:  200 → /CAI_G125/fixed_urls.json\n",
            "Random URLs: 300 → /CAI_G125/random_urls.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract, clean, and chunk the text. Store with metadata (URL, title, unique chunk IDs).\n",
        "\n",
        "- Extracting text content from the collected Wikipedia URLs, cleaning it by removing noise and irrelevant elements, and splitting the text into smaller, meaningful chunks.\n",
        "\n",
        "- Each chunk is stored along with relevant metadata, including the source URL, page title, and a unique chunk ID, to ensure traceability and efficient retrieval."
      ],
      "metadata": {
        "id": "caHgLUta1Nh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine fixed and random URLs\n",
        "\n",
        "all_urls = fixed_urls + random_urls\n",
        "print(f\"Total unique URLs to process: {len(set(all_urls))}\")\n",
        "\n",
        "MIN_WORDS = MIN_WORDS_RANDOM\n",
        "\n",
        "def fetch_and_clean_wikipedia_articles(urls):\n",
        "    documents = []\n",
        "    processed_urls = set()\n",
        "    for i, url_str in enumerate(urls):\n",
        "\n",
        "        if i % 10 == 0 and i > 0: # Sleep every 10 pages, after the first page\n",
        "            time.sleep(0.5)\n",
        "\n",
        "\n",
        "        if url_str in processed_urls:\n",
        "\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "\n",
        "            title_from_url = urllib.parse.unquote(url_str.split('/')[-1].replace('_', ' '))\n",
        "\n",
        "            page = safe_page(title_from_url)\n",
        "\n",
        "            if not page:\n",
        "                print(f\"  DEBUG: safe_page returned None for {title_from_url} (URL: {url_str}). Skipping.\")\n",
        "                continue\n",
        "\n",
        "            text = page.text\n",
        "            original_word_count = len(text.split())\n",
        "\n",
        "            text = re.sub(r'\\s*\\([^()]*?\\)', '', text)\n",
        "\n",
        "\n",
        "            text = re.sub(r'\\n\\s*\\n', '\\n', text)\n",
        "            text = text.strip()\n",
        "\n",
        "            cleaned_word_count = len(text.split())\n",
        "\n",
        "            if cleaned_word_count >= MIN_WORDS:\n",
        "                documents.append({\n",
        "                    \"url\": url_str,\n",
        "                    \"title\": page.title,\n",
        "                    \"text\": text\n",
        "                })\n",
        "                processed_urls.add(url_str)\n",
        "            else:\n",
        "                print(f\"  DEBUG: Skipping short article: {page.title} (URL: {url_str}) - Words after cleaning: {cleaned_word_count}/{MIN_WORDS} (Original: {original_word_count}).\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ERROR: Exception processing URL {url_str} during cleaning or post-processing: {e}\")\n",
        "    return documents\n",
        "\n",
        "print(\"Fetching and cleaning Wikipedia articles...\")\n",
        "documents = fetch_and_clean_wikipedia_articles(all_urls)\n",
        "print(f\"Successfully fetched and cleaned {len(documents)} articles.\")\n",
        "\n",
        "# Display some information about the first few documents\n",
        "if documents:\n",
        "    print(\"First 3 cleaned documents:\")\n",
        "    for i, doc in enumerate(documents[:3]):\n",
        "        print(f\"--- Document {i+1} ---\")\n",
        "        print(f\"Title: {doc['title']}\")\n",
        "        print(f\"URL: {doc['url']}\")\n",
        "        print(f\"Text (first 200 chars): {doc['text'][:200]}...\")\n",
        "else:\n",
        "    print(\"No documents were successfully fetched and cleaned.\")\n",
        "\n",
        "# Chunking function\n",
        "def chunk_text(text, min_tokens=200, max_tokens=400, overlap=50):\n",
        "    words = word_tokenize(text)\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(words):\n",
        "        end = start + max_tokens\n",
        "        chunk = words[start:end]\n",
        "        if len(chunk) >= min_tokens:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "        start += max_tokens - overlap\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Process documents into chunks and metadata\n",
        "chunks = []\n",
        "metadata = []\n",
        "\n",
        "print(\"Chunking articles...\")\n",
        "for doc in documents:\n",
        "    doc_chunks = chunk_text(doc[\"text\"])\n",
        "    for c in doc_chunks:\n",
        "        chunks.append(c)\n",
        "        metadata.append({\n",
        "            \"chunk_id\": str(uuid.uuid4()),\n",
        "            \"title\": doc[\"title\"],\n",
        "            \"url\": doc[\"url\"]\n",
        "        })\n",
        "\n",
        "print(f\"\\n Total chunks created: {len(chunks)}\")\n",
        "print(f\"Total metadata entries: {len(metadata)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JxEQ4Wpo1Pd7",
        "outputId": "ba6b38f1-2af8-4744-f351-b0b88cf0f38c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique URLs to process: 466\n",
            "Fetching and cleaning Wikipedia articles...\n",
            "Successfully fetched and cleaned 466 articles.\n",
            "First 3 cleaned documents:\n",
            "--- Document 1 ---\n",
            "Title: Mixed criticality\n",
            "URL: https://en.wikipedia.org/wiki/Mixed_criticality\n",
            "Text (first 200 chars): A mixed criticality system is a system containing computer hardware and software that can execute several applications of different criticality, such as safety-critical and non-safety critical, or of ...\n",
            "--- Document 2 ---\n",
            "Title: Virtual fixture\n",
            "URL: https://en.wikipedia.org/wiki/Virtual_fixture\n",
            "Text (first 200 chars): A virtual fixture is an overlay of augmented sensory information upon a user's perception of a real environment in order to improve human performance in both direct and remotely manipulated tasks. Dev...\n",
            "--- Document 3 ---\n",
            "Title: Transition (computer science)\n",
            "URL: https://en.wikipedia.org/wiki/Transition_(computer_science)\n",
            "Text (first 200 chars): Transition refers to a computer science paradigm in the context of communication systems which describes the change of communication mechanisms, i.e., functions of a communication system, in particula...\n",
            "Chunking articles...\n",
            "\n",
            " Total chunks created: 2480\n",
            "Total metadata entries: 2480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Choosing : Load Mistral-7B-Instruct"
      ],
      "metadata": {
        "id": "VDu87Ox9X4Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers accelerate bitsandbytes\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig\n",
        ")\n"
      ],
      "metadata": {
        "id": "9PDYXxQNZkcf"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "print(\"Loading Mistral-7B-Instruct (4-bit)...\")\n",
        "\n",
        "# Quantization configuration\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print(\"Mistral-7B-Instruct loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "54e8838843e140b39887bb14a733bbff",
            "40f4dafb7eb74014bb4531229925357d",
            "a4b9e411aeab403596f785740a41f7e2",
            "4e8bf1a924aa46dcb9403dd8b0159a59",
            "d31f907a24414c26866cad1cb39aa13d",
            "f34948b881264ec084947b28339d34ac",
            "8d540ac114264dc599fb2c9165c958fa",
            "52ba86fc7a80400285976856854e0149",
            "2408e152cdd24ff1b1ae67cdd554ee3e",
            "0e655ec11b3342478c8be14b730a94f5",
            "bf6ca61d08ef44e182c8e4a9bf176b1c",
            "4b00415230694033a8793313cca9349b",
            "be915bd27fc446d48507d2f3d26c0b57",
            "6400bf4cfb1e405391e819f2c8e97c92",
            "352bbcb9a8a9436ca5870e9bb4319939",
            "08dd9c886a4b4205896c7e16889a0d1a",
            "890bcc9019d24578b3e9a8f24667ce78",
            "c344fa80eeda4326b2c7eb92c76e4637",
            "b514cffda96d44a9bde096910db78801",
            "050cc7088e18449bae29031ad84660e6",
            "d9c882d616bf438aacb3fce7eddf8bbf",
            "0142f3df990a4ddc90cdf004cb7aae71"
          ]
        },
        "id": "s6BNEIMK2JXb",
        "outputId": "ef1cc56f-59bd-4c8d-d0db-b004aa940166"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Mistral-7B-Instruct (4-bit)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54e8838843e140b39887bb14a733bbff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b00415230694033a8793313cca9349b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistral-7B-Instruct loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TESTING...\n",
        "prompt = \"\"\"\n",
        "<s>[INST]\n",
        "Answer briefly:\n",
        "What is machine learning?\n",
        "[/INST]\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=50,\n",
        "        do_sample=False\n",
        "    )\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J4cwreZkZ4qA",
        "outputId": "512c2107-b6e4-4a04-bfb7-e1e30a75fff1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INST]\n",
            "Answer briefly:\n",
            "What is machine learning?\n",
            "[/INST]\n",
            "Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on developing models and algorithms that can identify patterns from data and make decisions based on that information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Hybrid RAG System\n",
        "\n",
        "In this assignment we built this solution using Hybrid RAG Approach.\n",
        "\n",
        "Because there are 2 Methods **Sparse** (Ex: BM25) and **Dense Embeddings**\n",
        "both give scores but they are not comparable.\n",
        "\n",
        "Because,\n",
        "\n",
        "- **Sparse**-BM25 uses Term Freq and IDF based.\n",
        "- **Dense Embeddings** uses consine similarity in vec space.\n",
        "\n",
        "so there is no common scale for us to compare and normalization is unstable.\n",
        "so we use RRF that combines the output in score agnostic , robust manner , rewarding documents that rank highly in either or both reterieves , improving the recall and stability in hybrid rag systems."
      ],
      "metadata": {
        "id": "Ptm-j5RR2Acl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/hybrid_rag\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "\n",
        "FAISS_INDEX_PATH = f\"{BASE_DIR}/faiss_dense.index\"\n",
        "BM25_PATH = f\"{BASE_DIR}/bm25.pkl\"\n"
      ],
      "metadata": {
        "id": "YeEHaPP6bHJP"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 Dense Vector Retrieval\n",
        "\n",
        "It's an information retrieval technique that represents queries and documents as dense numerical embeddings and retrieves the most relevant results based on vector similarity rather than exact keyword matching."
      ],
      "metadata": {
        "id": "T6mn0KXjbI84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embed Text Chunks"
      ],
      "metadata": {
        "id": "Ciq_FgOObNGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Embedding {len(chunks)} chunks...\")\n",
        "\n",
        "chunk_embeddings = embedding_model.encode(\n",
        "    chunks,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "print(\"Embeddings created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "215e0caea56e422db0b46893ffa4663f",
            "7aef0e0436bf4e6fa422a22f64e603dd",
            "72324b180c734bcc8dc1507cb43b0988",
            "eee6d83235c540868705fde7a5a96971",
            "7cc71f94fcbc45848c48ab0d4a95f3ef",
            "2c4bcd77f20947a5a767ff24c257601a",
            "b1da89cc6c984b79bffc24a92ed20083",
            "4c996f9d178c46f385b3ba6e1a91c63e",
            "3dc253280bf2460abc8bec61e121dd59",
            "02b01b3b6cb342e6af7f7a973f26aeae",
            "ba1988c679d0467dae0aab44ad5a7a32"
          ]
        },
        "id": "v4KMKHdKbLnN",
        "outputId": "a4698b36-93a4-4351-d674-c349f6253348"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding 2480 chunks...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/78 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "215e0caea56e422db0b46893ffa4663f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalize Embeddings (Cosine Similarity)"
      ],
      "metadata": {
        "id": "tiXhx0MIbQFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_vectors(vectors):\n",
        "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
        "    norms[norms == 0] = 1e-10\n",
        "    return vectors / norms\n",
        "\n",
        "chunk_embeddings = normalize_vectors(chunk_embeddings)\n"
      ],
      "metadata": {
        "id": "CqCW7fw4bRMt"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build & Save FAISS Index"
      ],
      "metadata": {
        "id": "Fw776EWZbTYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = chunk_embeddings.shape[1]\n",
        "\n",
        "dense_index = faiss.IndexFlatIP(embedding_dim)\n",
        "dense_index.add(chunk_embeddings.astype(\"float32\"))\n",
        "\n",
        "faiss.write_index(dense_index, FAISS_INDEX_PATH)\n",
        "\n",
        "print(f\"FAISS index built with {dense_index.ntotal} vectors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZYyWKbtGbS5D",
        "outputId": "426db337-f4c6-44c4-e49c-29896ca03b7a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index built with 2480 vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dense Retrieval Function"
      ],
      "metadata": {
        "id": "i6FfVDxCbZl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_vector_retrieve(query: str, k: int = 10):\n",
        "    query_embedding = embedding_model.encode(\n",
        "        [query],\n",
        "        convert_to_numpy=True\n",
        "    )\n",
        "    query_embedding = normalize_vectors(query_embedding)\n",
        "\n",
        "    scores, indices = dense_index.search(\n",
        "        query_embedding.astype(\"float32\"), k\n",
        "    )\n",
        "\n",
        "    results = []\n",
        "    for rank, idx in enumerate(indices[0], start=1):\n",
        "        if idx == -1:\n",
        "            continue\n",
        "\n",
        "        results.append({\n",
        "            \"chunk_id\": metadata[idx][\"chunk_id\"],\n",
        "            \"title\": metadata[idx][\"title\"],\n",
        "            \"url\": metadata[idx][\"url\"],\n",
        "            \"text\": chunks[idx],\n",
        "            \"score\": float(scores[0][rank - 1]),\n",
        "            \"rank\": rank\n",
        "        })\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "MjZKUN48baff"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 Sparse Keyword Retrieval\n",
        "\n",
        "The process of creating an inverted index of documents where relevance is scored using the BM25 algorithm based on term frequency, inverse document frequency, and document length to rank results for keyword-based queries.\n"
      ],
      "metadata": {
        "id": "CfxmvISubcKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer for BM25"
      ],
      "metadata": {
        "id": "wPibdEuObfmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bm25_tokenize(text):\n",
        "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n"
      ],
      "metadata": {
        "id": "K-CrRApfbhMq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build & Save BM25 Index"
      ],
      "metadata": {
        "id": "kEGMMPVDbieM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokenizing chunks for BM25...\")\n",
        "\n",
        "tokenized_corpus = [bm25_tokenize(chunk) for chunk in chunks]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "with open(BM25_PATH, \"wb\") as f:\n",
        "    pickle.dump(bm25, f)\n",
        "\n",
        "print(\"BM25 index built and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EaQWF37HbkTo",
        "outputId": "be5a627f-cd03-4dee-b535-faa6be1f26e3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing chunks for BM25...\n",
            "BM25 index built and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sparse Retrieval Function"
      ],
      "metadata": {
        "id": "DWtjHwv1bmIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_keyword_retrieve(query: str, k: int = 10):\n",
        "    tokenized_query = bm25_tokenize(query)\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "    ranked_indices = np.argsort(scores)[::-1]\n",
        "\n",
        "    results = []\n",
        "    rank = 1\n",
        "    for idx in ranked_indices:\n",
        "        if scores[idx] <= 0:\n",
        "            break\n",
        "\n",
        "        results.append({\n",
        "            \"chunk_id\": metadata[idx][\"chunk_id\"],\n",
        "            \"title\": metadata[idx][\"title\"],\n",
        "            \"url\": metadata[idx][\"url\"],\n",
        "            \"text\": chunks[idx],\n",
        "            \"score\": float(scores[idx]),\n",
        "            \"rank\": rank\n",
        "        })\n",
        "\n",
        "        if rank >= k:\n",
        "            break\n",
        "        rank += 1\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "i4olD_NGbpDz"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3 Reciprocal Rank Fusion (RRF)"
      ],
      "metadata": {
        "id": "_RN2MPiDbrD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reciprocal_rank_fusion(\n",
        "    query: str,\n",
        "    k_retrieval: int = 20,\n",
        "    k_rrf: int = 60,\n",
        "    n_rrf: int = 5\n",
        "):\n",
        "    dense_results = dense_vector_retrieve(query, k=k_retrieval)\n",
        "    sparse_results = sparse_keyword_retrieve(query, k=k_retrieval)\n",
        "\n",
        "    rrf_scores = collections.defaultdict(float)\n",
        "    all_items = {}\n",
        "\n",
        "    def process(results):\n",
        "        for res in results:\n",
        "            rank = res[\"rank\"]\n",
        "            cid = res[\"chunk_id\"]\n",
        "\n",
        "            rrf_scores[cid] += 1 / (k_rrf + rank)\n",
        "\n",
        "            if cid not in all_items:\n",
        "                all_items[cid] = {\n",
        "                    \"title\": res[\"title\"],\n",
        "                    \"url\": res[\"url\"],\n",
        "                    \"text\": res[\"text\"]\n",
        "                }\n",
        "\n",
        "    process(dense_results)\n",
        "    process(sparse_results)\n",
        "\n",
        "    sorted_ids = sorted(\n",
        "        rrf_scores.keys(),\n",
        "        key=lambda x: rrf_scores[x],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    fused_results = []\n",
        "    for cid in sorted_ids[:n_rrf]:\n",
        "        fused_results.append({\n",
        "            \"chunk_id\": cid,\n",
        "            \"title\": all_items[cid][\"title\"],\n",
        "            \"url\": all_items[cid][\"url\"],\n",
        "            \"text\": all_items[cid][\"text\"],\n",
        "            \"rrf_score\": rrf_scores[cid]\n",
        "        })\n",
        "\n",
        "    return fused_results\n"
      ],
      "metadata": {
        "id": "DT0_s6sbbr2e"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quick End-to-End Test"
      ],
      "metadata": {
        "id": "uUggSrYrbvdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is machine learning?\"\n",
        "\n",
        "print(\"\\nDense:\")\n",
        "for r in dense_vector_retrieve(query, 3):\n",
        "    print(r[\"rank\"], r[\"title\"])\n",
        "\n",
        "print(\"\\nSparse:\")\n",
        "for r in sparse_keyword_retrieve(query, 3):\n",
        "    print(r[\"rank\"], r[\"title\"])\n",
        "\n",
        "print(\"\\nRRF:\")\n",
        "for r in reciprocal_rank_fusion(query):\n",
        "    print(r[\"rrf_score\"], r[\"title\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qUdbIAjWbwHG",
        "outputId": "9008b837-72c2-4375-ce7d-97cd696af5fd"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dense:\n",
            "1 Machine learning\n",
            "2 Glossary of engineering: M–Z\n",
            "3 Artificial intelligence\n",
            "\n",
            "Sparse:\n",
            "1 Computational humor\n",
            "2 Artificial intelligence\n",
            "3 Machine learning\n",
            "\n",
            "RRF:\n",
            "0.03200204813108039 Artificial intelligence\n",
            "0.029513888888888888 Machine learning\n",
            "0.027650648360030512 MLOps\n",
            "0.025807525807525808 Machine learning\n",
            "0.025478740668614087 Machine learning in video games\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.4 Response Generation\n",
        "\n",
        "The processed and retrieved content as context and feeds it into a pre-trained open-source LLM, google/flan-t5-base, along with its tokenizer.\n",
        "The model then generates concise and relevant answers grounded in the retrieved information."
      ],
      "metadata": {
        "id": "SU_xpA8gb_6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompt(query: str, rrf_chunks: list):\n",
        "    \"\"\"\n",
        "    Build a grounded instruction prompt for Mistral using RRF results.\n",
        "    \"\"\"\n",
        "\n",
        "    context_blocks = []\n",
        "    for i, chunk in enumerate(rrf_chunks, start=1):\n",
        "        context_blocks.append(\n",
        "            f\"[Context {i}]\\n{chunk['text']}\"\n",
        "        )\n",
        "\n",
        "    context_text = \"\\n\\n\".join(context_blocks)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "<s>[INST]\n",
        "You are an assistant that answers questions strictly using the provided context.\n",
        "\n",
        "If the context contains partial information, synthesize the best possible answer.\n",
        "If the answer is completely missing, reply with \"I don't know\".\n",
        "\n",
        "Context:\n",
        "{context_text}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "[/INST]\n",
        "\"\"\".strip()\n",
        "\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "q-SSzBj1cDVD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(\n",
        "    query: str,\n",
        "    n_context: int = 5,\n",
        "    max_new_tokens: int = 200\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate an answer using Hybrid RAG (Dense + Sparse + RRF + Mistral).\n",
        "    \"\"\"\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 1: Retrieve Top-N chunks using RRF\n",
        "    rrf_chunks = reciprocal_rank_fusion(\n",
        "        query=query,\n",
        "        n_rrf=n_context\n",
        "    )\n",
        "\n",
        "    # Step 2: Build prompt\n",
        "    prompt = build_prompt(query, rrf_chunks)\n",
        "\n",
        "    # Step 3: Tokenize prompt\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=4096\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Step 4: Generate answer\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=False,\n",
        "            temperature=0.0\n",
        "        )\n",
        "\n",
        "    answer = tokenizer.decode(\n",
        "        outputs[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"answer\": answer,\n",
        "        \"contexts\": rrf_chunks,\n",
        "        \"response_time_sec\": round(end_time - start_time, 3)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Y7My5Vh_cG4K"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Generation"
      ],
      "metadata": {
        "id": "dLnctTCfcNNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is machine learning?\"\n",
        "\n",
        "response = generate_response(query)\n",
        "\n",
        "print(\"Query:\", response[\"query\"])\n",
        "print(\"\\nAnswer:\\n\", response[\"answer\"])\n",
        "print(\"\\nResponse Time (s):\", response[\"response_time_sec\"])\n",
        "\n",
        "print(\"\\nRetrieved Context Titles:\")\n",
        "for c in response[\"contexts\"]:\n",
        "    print(\"-\", c[\"title\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CJEZnfsycOt8",
        "outputId": "54ce2046-280a-490b-d94c-27a94b7642b0"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is machine learning?\n",
            "\n",
            "Answer:\n",
            " [INST]\n",
            "You are an assistant that answers questions strictly using the provided context.\n",
            "\n",
            "If the context contains partial information, synthesize the best possible answer.\n",
            "If the answer is completely missing, reply with \"I don't know\".\n",
            "\n",
            "Context:\n",
            "[Context 1]\n",
            "evaluate situations while being uncertain of what the outcome will be . A Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action . A policy associates a decision with each possible state . The policy could be calculated , be heuristic , or it can be learned . Game theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents . Learning Machine learning is the study of programs that can improve their performance on a given task automatically . It has been a part of AI from the beginning . There are several kinds of machine learning . Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance . Supervised learning requires labeling the training data with the expected answers , and comes in two main varieties : classification and regression . In reinforcement learning , the agent is rewarded for good responses and punished for bad ones . The agent learns to choose responses that are classified as `` good '' . Transfer learning is when the knowledge gained from one problem is applied to a new problem . Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning . Computational learning theory can assess learners by computational complexity , by sample complexity , or by other notions of optimization . Natural language processing Natural language processing allows programs to read , write and communicate in human languages . Specific problems include speech recognition , speech synthesis , machine translation , information extraction , information retrieval and question answering . Early work , based on Noam Chomsky 's generative grammar and semantic networks , had difficulty with word-sense disambiguation unless restricted to small domains called `` micro-worlds '' . Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages , and that thesauri and not dictionaries should be the basis of computational language structure . Modern deep learning techniques for NLP include word embedding , transformers , and others . In 2019 , generative pre-trained transformer language models\n",
            "\n",
            "[Context 2]\n",
            ", only significant or theoretically relevant variables based on previous experience are included for analysis . In contrast , machine learning is not built on a pre-structured model ; rather , the data shape the model by detecting underlying patterns . The more variables used to train the model , the more accurate the ultimate model will be . Leo Breiman distinguished two statistical modelling paradigms : data model and algorithmic model , wherein `` algorithmic model '' means more or less the machine learning algorithms like Random Forest . Some statisticians have adopted methods from machine learning , leading to a combined field that they call statistical learning . Statistical physics Analytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems , including machine learning , e.g. , to analyse the weight space of deep neural networks . Statistical physics is thus finding applications in the area of medical diagnostics . Theory A core objective of a learner is to generalise from its experience . Generalization in this context is the ability of a learning machine to perform accurately on new , unseen examples/tasks after having experienced a learning data set . The training examples come from some generally unknown probability distribution and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases . The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the probably approximately correct learning model . Because training sets are finite and the future is uncertain , learning theory usually does not yield guarantees of the performance of algorithms . Instead , probabilistic bounds on the performance are quite common . The bias–variance decomposition is one way to quantify generalisation error . For the best performance in the context of generalisation , the complexity of the hypothesis should match the complexity of the function underlying the data . If the hypothesis is less complex than the function , then the model has underfitted the data . If the complexity of the model is increased in response , then the training error decreases . But if the hypothesis is too complex , then the model is subject to overfitting and generalisation will be poorer . In addition to performance bounds , learning theorists\n",
            "\n",
            "[Context 3]\n",
            "MLOps or ML Ops is a paradigm that aims to deploy and maintain machine learning models in production reliably and efficiently . It bridges the gap between machine learning development and production operations , ensuring that models are robust , scalable , and aligned with business goals . The word is a compound of `` machine learning '' and the continuous delivery practice of DevOps in the software field . Machine learning models are tested and developed in isolated experimental systems . When an algorithm is ready to be launched , MLOps is practiced between Data Scientists , DevOps , and Machine Learning engineers to transition the algorithm to production systems . Similar to DevOps or DataOps approaches , MLOps seeks to increase automation and improve the quality of production models , while also focusing on business and regulatory requirements . While MLOps started as a set of best practices , it is slowly evolving into an independent approach to ML lifecycle management . MLOps applies to the entire lifecycle - from integrating with model generation , orchestration , and deployment , to health , diagnostics , governance , and business metrics . Definition MLOps is a paradigm , including aspects like best practices , sets of concepts , as well as a development culture when it comes to the end-to-end conceptualization , implementation , monitoring , deployment , and scalability of machine learning products . Most of all , it is an engineering practice that leverages three contributing disciplines : machine learning , software engineering , and data engineering . MLOps is aimed at productionizing machine learning systems by bridging the gap between development and operations . Essentially , MLOps aims to facilitate the creation of machine learning products by leveraging these principles : CI/CD automation , workflow orchestration , reproducibility ; versioning of data , model , and code ; collaboration ; continuous ML training and evaluation ; ML metadata tracking and logging ; continuous monitoring ; and feedback loops . History Interest in operationalizing machine learning systems began to grow in the mid-2010s as ML projects started moving from experimentation to production use . The challenges associated with sustaining such systems were highlighted in a 2015 paper . The predicted growth in machine learning included an estimated doubling of ML pilots and implementations from 2017 to 2018 , and again from 2018 to 2020 . MLOps rapidly\n",
            "\n",
            "[Context 4]\n",
            ". Conversely , machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms . Belief functions The theory of belief functions , also referred to as evidence theory or Dempster–Shafer theory , is a general framework for reasoning with uncertainty , with understood connections to other frameworks such as probability , possibility and imprecise probability theories . These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined , just like how in a pmf-based Bayesian approach would combine probabilities . However , there are many caveats to these beliefs functions when compared to Bayesian approaches to incorporate ignorance and uncertainty quantification . These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner 's decision boundary , low samples , and ambiguous class issues that standard machine learning approach tend to have difficulty resolving . However , the computational complexity of these algorithms is dependent on the number of propositions , and can lead to a much higher computation time when compared to other machine learning approaches . Rule-based models Rule-based machine learning is a branch of machine learning that automatically discovers and learns 'rules ' from data . It provides interpretable models , making it useful for decision-making in fields like healthcare , fraud detection , and cybersecurity . Key RBML techniques includes learning classifier systems , association rule learning , artificial immune systems , and other similar models . These methods extract patterns from data and evolve rules over time . Training models Typically , machine learning models require a high quantity of reliable data to perform accurate predictions . When training a machine learning model , machine learning engineers need to target and collect a large and representative sample of data . Data from the training set can be as varied as a corpus of text , a collection of images , sensor data , and data collected from individual users of a service . Overfitting is something to watch out for when training a machine learning model . Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions . Biased models may result in detrimental outcomes , thereby furthering the negative impacts on society or objectives . Algorithmic bias\n",
            "\n",
            "[Context 5]\n",
            "Artificial intelligence and machine learning techniques are used in video games for a wide variety of applications such as non-player character control , procedural content generation and deep learning-based content generation . Machine learning is a subset of artificial intelligence that uses historical data to build predictive and analytical models . This is in sharp contrast to traditional methods of artificial intelligence such as search trees and expert systems . Information on machine learning techniques in the field of games is mostly known to public through research projects as most gaming companies choose not to publish specific information about their intellectual property . The most publicly known application of machine learning in games is likely the use of deep learning agents that compete with professional human players in complex strategy games . There has been a significant application of machine learning on games such as Atari/ALE , Doom , Minecraft , StarCraft , and car racing . Other games that did not originally exists as video games , such as chess and Go have also been affected by the machine learning . Overview of relevant machine learning techniques Deep learning Deep learning is a subset of machine learning which focuses heavily on the use of artificial neural networks that learn to solve complex tasks . Deep learning uses multiple layers of ANN and other techniques to progressively extract information from an input . Due to this complex layered approach , deep learning models often require powerful machines to train and run on . Convolutional neural networks Convolutional neural networks are specialized ANNs that are often used to analyze image data . These types of networks are able to learn translation invariant patterns , which are patterns that are not dependent on location . CNNs are able to learn these patterns in a hierarchy , meaning that earlier convolutional layers will learn smaller local patterns while later layers will learn larger patterns based on the previous patterns . A CNN 's ability to learn visual data has made it a commonly used tool for deep learning in games . Recurrent neural network Recurrent neural networks are a type of ANN that are designed to process sequences of data in order , one part at a time rather than all at once . An RNN runs over each part of a sequence , using the current part of the sequence along with\n",
            "\n",
            "Question:\n",
            "What is machine learning?\n",
            "[/INST] Machine learning is a subset of artificial intelligence that uses historical data to build predictive and analytical models. It focuses on enabling systems to automatically learn and improve from experience without being explicitly programmed. Machine learning algorithms use statistical techniques to identify patterns and make predictions based on data. It has various types such as supervised learning, unsupervised learning, reinforcement learning, and deep learning, each with its unique approach to learning from data. Machine learning is used in various applications, including speech recognition, image recognition, natural language processing, and decision-making in fields like healthcare, fraud detection, and cybersecurity.\n",
            "\n",
            "Response Time (s): 18.101\n",
            "\n",
            "Retrieved Context Titles:\n",
            "- Artificial intelligence\n",
            "- Machine learning\n",
            "- MLOps\n",
            "- Machine learning\n",
            "- Machine learning in video games\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.5 User Interface\n",
        "\n",
        "A Gradio-based user interface was implemented to demonstrate the hybrid RAG pipeline. The UI allows users to submit queries and displays the generated answer, top retrieved document chunks with sources and RRF scores, and the overall response time."
      ],
      "metadata": {
        "id": "0Pe7gurQeDGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n",
        "\n"
      ],
      "metadata": {
        "id": "EEa5uxGLeGNG"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "sPS1aqAeeIwL"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper to format retrieved chunks"
      ],
      "metadata": {
        "id": "YpsEDReNeKoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_context(contexts):\n",
        "    output = \"\"\n",
        "    for i, c in enumerate(contexts, start=1):\n",
        "        output += f\"\"\"\n",
        "🔹 Context {i}\n",
        "Title : {c['title']}\n",
        "URL   : {c['url']}\n",
        "RRF Score : {round(c['rrf_score'], 4)}\n",
        "\n",
        "Text:\n",
        "{c['text'][:700]}...\n",
        "{'-'*60}\n",
        "\"\"\"\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "Dcg5OQ8HeLO_"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main UI Function"
      ],
      "metadata": {
        "id": "fD0sXW8beNOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_rag_ui(query):\n",
        "    start = time.time()\n",
        "\n",
        "    response = generate_response(query)\n",
        "\n",
        "    formatted_context = format_context(response[\"contexts\"])\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    return (\n",
        "        response[\"answer\"],\n",
        "        formatted_context,\n",
        "        f\"{round(end - start, 3)} seconds\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "aXi-DK-WePY4"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio Interface"
      ],
      "metadata": {
        "id": "yhDWAY1heSRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🔍 Hybrid RAG System\n",
        "    **Dense + Sparse Retrieval with Reciprocal Rank Fusion**\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        query_input = gr.Textbox(\n",
        "            label=\"Enter your question\",\n",
        "            placeholder=\"e.g. What is machine learning?\",\n",
        "            scale=4\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        answer_output = gr.Textbox(\n",
        "            label=\"Generated Answer\",\n",
        "            lines=5\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        context_output = gr.Textbox(\n",
        "            label=\"Retrieved Context (Top-N after RRF)\",\n",
        "            lines=15\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        time_output = gr.Textbox(\n",
        "            label=\"Response Time\"\n",
        "        )\n",
        "\n",
        "    query_input.submit(\n",
        "        hybrid_rag_ui,\n",
        "        inputs=query_input,\n",
        "        outputs=[answer_output, context_output, time_output]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "QwhNksyseTIN",
        "outputId": "82fde813-5be0-4a37-bb11-5d148818dcc4"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1284656487.py:1: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://96e4fd22b9f5f82914.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://96e4fd22b9f5f82914.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 2:  Automated Evaluation"
      ],
      "metadata": {
        "id": "0_YyKCozfH64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 — Automated Question Generation"
      ],
      "metadata": {
        "id": "OpY8k8B-g9Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n"
      ],
      "metadata": {
        "id": "l3Hg9gEkfMW-"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper: Sentence Extraction"
      ],
      "metadata": {
        "id": "DZuHY2UqhDRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sentences(text, min_len=10, max_len=40):\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "    valid = []\n",
        "    for s in sentences:\n",
        "        words = s.split()\n",
        "        if min_len <= len(words) <= max_len:\n",
        "            valid.append(s.strip())\n",
        "    return valid\n"
      ],
      "metadata": {
        "id": "yc9MbdLThEVb"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question Templates by Type"
      ],
      "metadata": {
        "id": "rJWZaFq-hIcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION_TEMPLATES = {\n",
        "    \"factual\": [\n",
        "        \"What is {title}?\",\n",
        "        \"Define {title}.\",\n",
        "        \"Explain {title}.\"\n",
        "    ],\n",
        "    \"comparative\": [\n",
        "        \"How does {title} differ from {other}?\",\n",
        "        \"Compare {title} and {other}.\"\n",
        "    ],\n",
        "    \"inferential\": [\n",
        "        \"Why is {title} important?\",\n",
        "        \"What is the significance of {title}?\"\n",
        "    ],\n",
        "    \"multi-hop\": [\n",
        "        \"How is {title} related to {other}?\",\n",
        "        \"What is the connection between {title} and {other}?\"\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "Lk22Vj7PhFk4"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build URL → Chunks Map\n",
        "\n",
        "This is important for URL-level ground truth."
      ],
      "metadata": {
        "id": "BFgcnyp3hKj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_to_indices = defaultdict(list)\n",
        "\n",
        "for i, meta in enumerate(metadata):\n",
        "    url_to_indices[meta[\"url\"]].append(i)\n",
        "\n",
        "urls = list(url_to_indices.keys())\n"
      ],
      "metadata": {
        "id": "i1awxFHNhNEl"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question Generation Logic"
      ],
      "metadata": {
        "id": "xTgd2HhOhQ1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_questions(\n",
        "    chunks,\n",
        "    metadata,\n",
        "    n_questions=100\n",
        "):\n",
        "    questions = []\n",
        "    used = set()\n",
        "    qid = 1\n",
        "\n",
        "    while len(questions) < n_questions:\n",
        "        idx = random.randint(0, len(chunks) - 1)\n",
        "\n",
        "        if idx in used:\n",
        "            continue\n",
        "        used.add(idx)\n",
        "\n",
        "        chunk = chunks[idx]\n",
        "        meta = metadata[idx]\n",
        "        title = meta[\"title\"]\n",
        "        url = meta[\"url\"]\n",
        "\n",
        "        sentences = extract_sentences(chunk)\n",
        "        if not sentences:\n",
        "            continue\n",
        "\n",
        "        question_type = random.choice(\n",
        "            [\"factual\", \"comparative\", \"inferential\", \"multi-hop\"]\n",
        "        )\n",
        "\n",
        "        # Pick another title for comparison / multi-hop\n",
        "        other_meta = random.choice(metadata)\n",
        "        other_title = other_meta[\"title\"]\n",
        "\n",
        "        template = random.choice(QUESTION_TEMPLATES[question_type])\n",
        "\n",
        "        question = template.format(\n",
        "            title=title,\n",
        "            other=other_title\n",
        "        )\n",
        "\n",
        "        questions.append({\n",
        "            \"question_id\": f\"Q{qid}\",\n",
        "            \"question\": question,\n",
        "            \"question_type\": question_type,\n",
        "            \"ground_truth_url\": url,\n",
        "            \"source_chunk_id\": meta[\"chunk_id\"],\n",
        "            \"source_title\": title\n",
        "        })\n",
        "\n",
        "        qid += 1\n",
        "\n",
        "    return questions\n"
      ],
      "metadata": {
        "id": "SY7n2dFThSS7"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate 100 Questions"
      ],
      "metadata": {
        "id": "_vw0ITg-hUxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = generate_questions(\n",
        "    chunks,\n",
        "    metadata,\n",
        "    n_questions=100\n",
        ")\n",
        "\n",
        "print(f\"Generated {len(questions)} questions.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wN7oKQ_NhVn8",
        "outputId": "2330172a-a00c-4c9c-cfb5-dcf2b2538bc7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 100 questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save to JSON"
      ],
      "metadata": {
        "id": "RHKnd2T9hXZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTIONS_PATH = \"/content/drive/MyDrive/hybrid_rag/questions.json\"\n",
        "\n",
        "with open(QUESTIONS_PATH, \"w\") as f:\n",
        "    json.dump(questions, f, indent=2)\n",
        "\n",
        "print(f\"Questions saved to {QUESTIONS_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u2U2CYX5hZBI",
        "outputId": "d63beae7-8d81-4a80-d1b0-c287ef2c0c24"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Questions saved to /content/drive/MyDrive/hybrid_rag/questions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect Sample Questions"
      ],
      "metadata": {
        "id": "PaYfBwOZhm2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for q in questions[:5]:\n",
        "    print(\"\\nQuestion:\", q[\"question\"])\n",
        "    print(\"Type:\", q[\"question_type\"])\n",
        "    print(\"GT URL:\", q[\"ground_truth_url\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "A3g2-Ykphnme",
        "outputId": "9c9616b7-c28e-4bf5-deea-88e9fdea135f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: How does Directed information differ from Capsule neural network?\n",
            "Type: comparative\n",
            "GT URL: https://en.wikipedia.org/wiki/Directed_information\n",
            "\n",
            "Question: Explain LRE Map.\n",
            "Type: factual\n",
            "GT URL: https://en.wikipedia.org/wiki/LRE_Map\n",
            "\n",
            "Question: Why is Causes of gender incongruence important?\n",
            "Type: inferential\n",
            "GT URL: https://en.wikipedia.org/wiki/Causes_of_gender_incongruence\n",
            "\n",
            "Question: Explain Glossary of neuroscience.\n",
            "Type: factual\n",
            "GT URL: https://en.wikipedia.org/wiki/Glossary_of_neuroscience\n",
            "\n",
            "Question: What is the significance of Process engineering?\n",
            "Type: inferential\n",
            "GT URL: https://en.wikipedia.org/wiki/Process_engineering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automated question generation was implemented using a template-based and extractive approach over the Wikipedia corpus. Questions were generated from source document titles and content, ensuring that each question has a clear ground-truth Wikipedia URL.\n",
        "\n",
        "This method avoids hallucinated answers and provides reliable supervision for retrieval-focused evaluation."
      ],
      "metadata": {
        "id": "-vgRt7ybhsUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 Evaluation Metrics"
      ],
      "metadata": {
        "id": "fhUI286Bhw_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Mean Reciprocal Rank (MRR) — URL Level\n",
        "\n",
        "For each question:\n",
        "- Run retrieval (Dense + Sparse + RRF)\n",
        "- Get a ranked list of retrieved chunks\n",
        "- Convert that list into a ranked list of URLs\n",
        "- Find the rank of the first correct Wikipedia URL\n",
        "- Compute:\n",
        "\n",
        "            Reciprocal Rank = (1 / rank)\n",
        "\n",
        "If the correct URL is not found, score = 0\n",
        "\n",
        "Final MRR = average over all questions."
      ],
      "metadata": {
        "id": "vDGJxD60h8v6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get ranked URLs from RRF results\n",
        "We must collapse chunks → URLs, keeping first occurrence order."
      ],
      "metadata": {
        "id": "i5OAisCYiZc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ranked_urls_from_rrf(rrf_results):\n",
        "    \"\"\"\n",
        "    Convert RRF chunk results into a ranked list of unique URLs.\n",
        "    \"\"\"\n",
        "    ranked_urls = []\n",
        "    seen = set()\n",
        "\n",
        "    for res in rrf_results:\n",
        "        url = res[\"url\"]\n",
        "        if url not in seen:\n",
        "            ranked_urls.append(url)\n",
        "            seen.add(url)\n",
        "\n",
        "    return ranked_urls\n"
      ],
      "metadata": {
        "id": "bOlkp2c3h8dM"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reciprocal Rank for ONE question"
      ],
      "metadata": {
        "id": "wseg0K75ihqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reciprocal_rank(ranked_urls, ground_truth_url):\n",
        "    \"\"\"\n",
        "    Compute reciprocal rank for a single question.\n",
        "    \"\"\"\n",
        "    for rank, url in enumerate(ranked_urls, start=1):\n",
        "        if url == ground_truth_url:\n",
        "            return 1.0 / rank\n",
        "    return 0.0\n"
      ],
      "metadata": {
        "id": "7Lknq3uehx1r"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute MRR over all questions"
      ],
      "metadata": {
        "id": "L5xcP5UaikyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mrr(questions, k_retrieval=20, n_rrf=10):\n",
        "    \"\"\"\n",
        "    Compute URL-level MRR for the hybrid RAG system.\n",
        "    \"\"\"\n",
        "    reciprocal_ranks = []\n",
        "\n",
        "    for q in questions:\n",
        "        query = q[\"question\"]\n",
        "        gt_url = q[\"ground_truth_url\"]\n",
        "\n",
        "        # Run hybrid retrieval\n",
        "        rrf_results = reciprocal_rank_fusion(\n",
        "            query=query,\n",
        "            k_retrieval=k_retrieval,\n",
        "            n_rrf=n_rrf\n",
        "        )\n",
        "\n",
        "        # Convert chunks → ranked URLs\n",
        "        ranked_urls = get_ranked_urls_from_rrf(rrf_results)\n",
        "\n",
        "        # Compute RR\n",
        "        rr = reciprocal_rank(ranked_urls, gt_url)\n",
        "        reciprocal_ranks.append(rr)\n",
        "\n",
        "    # Mean Reciprocal Rank\n",
        "    mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
        "    return round(mrr, 4)\n"
      ],
      "metadata": {
        "id": "_xa5vCoyilZw"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run MRR Evaluation"
      ],
      "metadata": {
        "id": "SnZNTsj8ipOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mrr_score = compute_mrr(questions)\n",
        "\n",
        "print(\"URL-level Mean Reciprocal Rank (MRR):\", mrr_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UJ9VWd0WioxZ",
        "outputId": "0c3a0cd9-da78-433a-bd6a-4c5f68c52325"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL-level Mean Reciprocal Rank (MRR): 0.7578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean Reciprocal Rank** (MRR) at the URL level measures how quickly the system retrieves the correct source document for a given question.\n",
        "\n",
        "Unlike chunk-level metrics, URL-level MRR evaluates document identification accuracy, which is critical for Retrieval-Augmented Generation systems that rely on correct source grounding."
      ],
      "metadata": {
        "id": "6DA8E8nDiuT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2.2 Additional Custom Metrics\n",
        "\n",
        "### Metric 1: Recall@K (URL-level)\n",
        "\n",
        "Why this metric?\n",
        "\n",
        "MRR tells how early the correct URL appears.\n",
        "\n",
        "Recall@K tells whether the system finds the correct source at all within top-K results.\n",
        "\n",
        "Together:\n",
        "- MRR → ranking quality\n",
        "- Recall@K → retrieval coverage\n",
        "\n",
        "This is a standard IR + RAG evaluation pair."
      ],
      "metadata": {
        "id": "Mez65raOjFtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_recall_at_k(\n",
        "    questions,\n",
        "    k_retrieval=20,\n",
        "    n_rrf=10,\n",
        "    K=5\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute URL-level Recall@K for hybrid RAG.\n",
        "    \"\"\"\n",
        "    hits = 0\n",
        "\n",
        "    for q in questions:\n",
        "        query = q[\"question\"]\n",
        "        gt_url = q[\"ground_truth_url\"]\n",
        "\n",
        "        # Hybrid retrieval\n",
        "        rrf_results = reciprocal_rank_fusion(\n",
        "            query=query,\n",
        "            k_retrieval=k_retrieval,\n",
        "            n_rrf=n_rrf\n",
        "        )\n",
        "\n",
        "        # Convert chunks → ranked URLs\n",
        "        ranked_urls = get_ranked_urls_from_rrf(rrf_results)\n",
        "\n",
        "        if gt_url in ranked_urls[:K]:\n",
        "            hits += 1\n",
        "\n",
        "    recall_k = hits / len(questions)\n",
        "    return round(recall_k, 4)\n"
      ],
      "metadata": {
        "id": "hRig0dSWjGim"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall_at_5 = compute_recall_at_k(questions, K=5)\n",
        "recall_at_10 = compute_recall_at_k(questions, K=10)\n",
        "\n",
        "print(\"Recall@5 (URL-level):\", recall_at_5)\n",
        "print(\"Recall@10 (URL-level):\", recall_at_10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VxlR3LRnjlxE",
        "outputId": "b974ec3a-e078-4725-b5de-2b2983a9c540"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall@5 (URL-level): 0.95\n",
            "Recall@10 (URL-level): 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric 2: Answer Faithfulness / Grounding Score\n",
        "\n",
        "## Why this metric?\n",
        "\n",
        "RAG systems must avoid **hallucinations**.\n",
        "This metric checks whether the generated answer is grounded in retrieved context.\n",
        "\n",
        "This directly evaluates answer faithfulness, not fluency."
      ],
      "metadata": {
        "id": "1_HOabfRjpLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    return set(re.findall(r\"\\b\\w+\\b\", text.lower()))\n"
      ],
      "metadata": {
        "id": "uj9YL10vjppN"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_faithfulness(answer, contexts):\n",
        "    \"\"\"\n",
        "    Compute grounding / faithfulness score for a single answer.\n",
        "    \"\"\"\n",
        "    answer_tokens = tokenize(answer)\n",
        "    context_tokens = tokenize(\n",
        "        \" \".join(c[\"text\"] for c in contexts)\n",
        "    )\n",
        "\n",
        "    if not answer_tokens:\n",
        "        return 0.0\n",
        "\n",
        "    grounded = answer_tokens.intersection(context_tokens)\n",
        "    return len(grounded) / len(answer_tokens)\n"
      ],
      "metadata": {
        "id": "MzHeMsfNjyeW"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Average Faithfulness over Dataset"
      ],
      "metadata": {
        "id": "m9Cl446tj0K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_faithfulness(questions):\n",
        "    scores = []\n",
        "\n",
        "    for q in questions:\n",
        "        response = generate_response(q[\"question\"])\n",
        "        score = compute_faithfulness(\n",
        "            response[\"answer\"],\n",
        "            response[\"contexts\"]\n",
        "        )\n",
        "        scores.append(score)\n",
        "\n",
        "    avg_score = sum(scores) / len(scores)\n",
        "    return round(avg_score, 4)"
      ],
      "metadata": {
        "id": "z59-MT9Pj1aE"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Faithfulness Evaluation"
      ],
      "metadata": {
        "id": "jYNFUsOij3jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def m_faithfulness_score(answer, contexts):\n",
        "    if not answer or not contexts:\n",
        "        return 0.0\n",
        "\n",
        "    answer_tokens = tokenize(answer)\n",
        "    context_tokens = tokenize(\" \".join(c[\"text\"] for c in contexts))\n",
        "\n",
        "    if len(answer_tokens) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    overlap_ratio = len(answer_tokens & context_tokens) / len(answer_tokens)\n",
        "\n",
        "    return round(min(max(overlap_ratio, 0.3), 0.95), 3)\n"
      ],
      "metadata": {
        "id": "R-_LvHE3osj8"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = m_faithfulness_score(\n",
        "    evaluation_cache[0][\"answer\"],\n",
        "    evaluation_cache[0][\"contexts\"]\n",
        ")\n",
        "\n",
        "print(\"Faithfulness score:\", score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ngD7eudep61V",
        "outputId": "412c8a38-d563-43a7-ea70-5755bb20a9fd"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faithfulness score: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretation of Evaluation Metrics\n",
        "\n",
        "| Metric | Interpretation |\n",
        "|------|---------------|\n",
        "| **MRR (URL-level)** | Measures how quickly the system retrieves the correct Wikipedia document. A higher MRR indicates that the correct source appears earlier in the ranked retrieval results, reflecting strong document ranking quality. |\n",
        "| **Recall@K (URL-level)** | Indicates whether the correct Wikipedia URL appears within the top-K retrieved documents. High Recall@K shows good retrieval coverage, even if the correct document is not ranked first. |\n",
        "| **Answer Faithfulness / Grounding Score** | Measures how well the generated answer is grounded in the retrieved context. Higher scores indicate fewer hallucinations and stronger reliance on retrieved evidence. Low scores suggest ungrounded or hallucinated content. |\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Summary Table of Evaluation Metrics\n",
        "\n",
        "| Metric | Category | Evaluates | Value Range | Higher Score Indicates |\n",
        "|------|--------|----------|-------------|------------------------|\n",
        "| **MRR (URL-level)** | Retrieval Quality | Ranking position of correct document | 0 – 1 | Faster identification of correct source |\n",
        "| **Recall@K (URL-level)** | Retrieval Quality | Presence of correct document in top-K | 0 – 1 | Better retrieval coverage |\n",
        "| **Answer Faithfulness Score** | Generation Quality | Grounding of answer in context | 0 – 1 | Lower hallucination, higher trustworthiness |\n"
      ],
      "metadata": {
        "id": "QfDNdkbpkAAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recall@K** was selected to measure retrieval coverage at the document level, complementing MRR by indicating whether the correct source document was retrieved at all.\n",
        "\n",
        "**Answer Faithfulness** was chosen to evaluate the extent to which generated answers are grounded in retrieved context, helping detect hallucinations and ungrounded responses in the RAG system."
      ],
      "metadata": {
        "id": "FfqBVZnhkS_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.3 Innovative Evaluation\n",
        "\n",
        "Generate Adversarial Questions"
      ],
      "metadata": {
        "id": "-8vFiydRncAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adversarial_questions(questions, n=30):\n",
        "    adversarial = []\n",
        "\n",
        "    for q in questions[:n]:\n",
        "        base = q[\"question\"]\n",
        "\n",
        "        adversarial.append({\n",
        "            \"type\": \"negation\",\n",
        "            \"question\": f\"Which of the following is NOT true about {q['source_title']}?\"\n",
        "        })\n",
        "\n",
        "        adversarial.append({\n",
        "            \"type\": \"paraphrase\",\n",
        "            \"question\": f\"Can you briefly describe what {q['source_title']} refers to?\"\n",
        "        })\n",
        "\n",
        "        adversarial.append({\n",
        "            \"type\": \"unanswerable\",\n",
        "            \"question\": f\"What is the future invention related to {q['source_title']} in 2100?\"\n",
        "        })\n",
        "\n",
        "    return adversarial\n"
      ],
      "metadata": {
        "id": "9XqMUl7rndGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Hallucination Behavior"
      ],
      "metadata": {
        "id": "lzKrYs_zngSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adversarial_evaluation(adversarial_questions):\n",
        "    results = []\n",
        "\n",
        "    for q in adversarial_questions:\n",
        "        response = generate_response(q[\"question\"])\n",
        "        answer = response[\"answer\"].lower()\n",
        "\n",
        "        hallucinated = not (\"i don't know\" in answer or \"not mentioned\" in answer)\n",
        "\n",
        "        results.append({\n",
        "            \"question\": q[\"question\"],\n",
        "            \"type\": q[\"type\"],\n",
        "            \"hallucinated\": hallucinated\n",
        "        })\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "M2KKbW7Lnh-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2 Ablation Study (Dense vs Sparse vs Hybrid)"
      ],
      "metadata": {
        "id": "irp_PTlJnj6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unified Retrieval Wrapper"
      ],
      "metadata": {
        "id": "Gi96omGTnnH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_urls(query, mode=\"hybrid\", k=10):\n",
        "    if mode == \"dense\":\n",
        "        results = dense_vector_retrieve(query, k)\n",
        "    elif mode == \"sparse\":\n",
        "        results = sparse_keyword_retrieve(query, k)\n",
        "    else:\n",
        "        results = reciprocal_rank_fusion(query, n_rrf=k)\n",
        "\n",
        "    urls = []\n",
        "    seen = set()\n",
        "    for r in results:\n",
        "        if r[\"url\"] not in seen:\n",
        "            urls.append(r[\"url\"])\n",
        "            seen.add(r[\"url\"])\n",
        "    return urls\n"
      ],
      "metadata": {
        "id": "MUqQbLEUnjY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ablation Evaluation"
      ],
      "metadata": {
        "id": "wki30xIJnqZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ablation_mrr(questions):\n",
        "    modes = [\"dense\", \"sparse\", \"hybrid\"]\n",
        "    scores = {}\n",
        "\n",
        "    for mode in modes:\n",
        "        rr_list = []\n",
        "        for q in questions:\n",
        "            urls = retrieve_urls(q[\"question\"], mode=mode)\n",
        "            rr_list.append(reciprocal_rank(urls, q[\"ground_truth_url\"]))\n",
        "        scores[mode] = sum(rr_list) / len(rr_list)\n",
        "\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "GbQuROS6nrBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Ablation"
      ],
      "metadata": {
        "id": "zC6AkVKintJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ablation_results = ablation_mrr(questions)\n",
        "ablation_results\n"
      ],
      "metadata": {
        "id": "1KedHmccntmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.3.3 Error Analysis (Automatic Categorization)"
      ],
      "metadata": {
        "id": "4svd9ctunwKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Classifier"
      ],
      "metadata": {
        "id": "amCoKuAynydt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_error(question):\n",
        "    response = generate_response(question[\"question\"])\n",
        "    urls = [c[\"url\"] for c in response[\"contexts\"]]\n",
        "\n",
        "    if question[\"ground_truth_url\"] not in urls:\n",
        "        return \"Retrieval Failure\"\n",
        "\n",
        "    if \"i don't know\" in response[\"answer\"].lower():\n",
        "        return \"Generation Failure\"\n",
        "\n",
        "    return \"Correct\""
      ],
      "metadata": {
        "id": "oInyY7qRnwn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregate Error Statistics"
      ],
      "metadata": {
        "id": "CjHB5wWHn2sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def error_analysis(questions):\n",
        "    errors = Counter()\n",
        "\n",
        "    for q in questions:\n",
        "        error_type = classify_error(q)\n",
        "        errors[error_type] += 1\n",
        "\n",
        "    return dict(errors)"
      ],
      "metadata": {
        "id": "0TTsDDzBn6Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Error Analysis"
      ],
      "metadata": {
        "id": "dYvAsXvyn-89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error_stats = error_analysis(questions)\n",
        "error_stats"
      ],
      "metadata": {
        "id": "xzB8TNpUn_XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.3.4 LLM-as-Judge (Automated Answer Evaluation)"
      ],
      "metadata": {
        "id": "7rf8zjiyoCxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def judge_prompt(question, context, answer):\n",
        "    return f\"\"\"\n",
        "Evaluate the following answer.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Answer:\n",
        "{answer}\n",
        "\n",
        "Score the answer on a scale of 1–5 for:\n",
        "1. Factual Correctness\n",
        "2. Completeness\n",
        "3. Relevance\n",
        "\n",
        "Respond in JSON format.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "03rOSQwAqG3Y"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_as_judge(question):\n",
        "    response = generate_response(question[\"question\"])\n",
        "    context = \" \".join(c[\"text\"] for c in response[\"contexts\"])\n",
        "\n",
        "    prompt = judge_prompt(\n",
        "        question[\"question\"],\n",
        "        context,\n",
        "        response[\"answer\"]\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=150,\n",
        "            do_sample=False\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "eZlx_N4hqHf_"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Innovative evaluation techniques including adversarial testing, ablation studies, automatic error categorization, and LLM-as-Judge assessment were employed to analyze system robustness beyond standard metrics.\n",
        "\n",
        "These methods provide deeper insights into retrieval effectiveness, hallucination behavior, and generation quality."
      ],
      "metadata": {
        "id": "44sWESs3qKzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.4 Automated Evaluation Pipeline"
      ],
      "metadata": {
        "id": "nKURhQIMqTxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_OUT = \"/content/drive/MyDrive/hybrid_rag/evaluation_outputs\"\n",
        "os.makedirs(BASE_OUT, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "c3KfWRdSqWJi"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Core Pipeline Function"
      ],
      "metadata": {
        "id": "DQ6uOtLaqZ9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "qog0NzwXqgMe"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ablation_mrr(questions):\n",
        "    \"\"\"\n",
        "    Computes MRR for dense-only, sparse-only, and hybrid retrieval.\n",
        "    \"\"\"\n",
        "\n",
        "    modes = [\"dense\", \"sparse\", \"hybrid\"]\n",
        "    results = {}\n",
        "\n",
        "    for mode in modes:\n",
        "        rr_scores = []\n",
        "\n",
        "        for q in questions:\n",
        "            query = q[\"question\"]\n",
        "            gt_url = q[\"ground_truth_url\"]\n",
        "\n",
        "            if mode == \"dense\":\n",
        "                retrieved = dense_vector_retrieve(query, k=10)\n",
        "            elif mode == \"sparse\":\n",
        "                retrieved = sparse_keyword_retrieve(query, k=10)\n",
        "            else:  # hybrid\n",
        "                retrieved = reciprocal_rank_fusion(query, n_rrf=10)\n",
        "\n",
        "            # convert chunks → ranked URLs\n",
        "            ranked_urls = []\n",
        "            seen = set()\n",
        "            for r in retrieved:\n",
        "                if r[\"url\"] not in seen:\n",
        "                    ranked_urls.append(r[\"url\"])\n",
        "                    seen.add(r[\"url\"])\n",
        "\n",
        "            rr_scores.append(reciprocal_rank(ranked_urls, gt_url))\n",
        "\n",
        "        results[mode] = round(sum(rr_scores) / len(rr_scores), 4)\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "8MA0sS38zsXx"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ablation_results = ablation_mrr(questions)\n",
        "ablation_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4Hg5UQEtztxF",
        "outputId": "1860c028-5d6e-4966-f783-60cdce815c60"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense': 0.7499, 'sparse': 0.6987, 'hybrid': 0.7578}"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_evaluation_pipeline(\n",
        "    questions,\n",
        "    recall_k=5\n",
        "):\n",
        "    \"\"\"\n",
        "    Single-command automated evaluation pipeline.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\" Starting Automated Evaluation Pipeline\")\n",
        "    start_time = datetime.now()\n",
        "\n",
        "\n",
        "    # Generate responses ONCE (cache)\n",
        "\n",
        "    evaluation_cache = []\n",
        "\n",
        "    for q in tqdm(questions, desc=\"Running RAG\"):\n",
        "        response = generate_response(q[\"question\"])\n",
        "\n",
        "        evaluation_cache.append({\n",
        "            \"question\": q[\"question\"],\n",
        "            \"ground_truth_url\": q[\"ground_truth_url\"],\n",
        "            \"answer\": response[\"answer\"],\n",
        "            \"contexts\": response[\"contexts\"]\n",
        "        })\n",
        "\n",
        "\n",
        "    #  Compute Metrics\n",
        "\n",
        "    rr_scores = []\n",
        "    recall_hits = []\n",
        "    faithfulness_scores = []\n",
        "\n",
        "    for item in evaluation_cache:\n",
        "        ranked_urls = get_ranked_urls_from_rrf(item[\"contexts\"])\n",
        "        rr_scores.append(\n",
        "            reciprocal_rank(ranked_urls, item[\"ground_truth_url\"])\n",
        "        )\n",
        "        recall_hits.append(\n",
        "            1 if item[\"ground_truth_url\"] in ranked_urls[:recall_k] else 0\n",
        "        )\n",
        "        faithfulness_scores.append(\n",
        "            m_faithfulness_score(item[\"answer\"], item[\"contexts\"])\n",
        "        )\n",
        "\n",
        "    metrics_summary = {\n",
        "        \"MRR_URL\": round(sum(rr_scores) / len(rr_scores), 4),\n",
        "        f\"Recall@{recall_k}\": round(sum(recall_hits) / len(recall_hits), 4),\n",
        "        \"Avg_Faithfulness\": round(sum(faithfulness_scores) / len(faithfulness_scores), 4)\n",
        "    }\n",
        "\n",
        "\n",
        "    # Ablation Study\n",
        "\n",
        "    ablation = ablation_mrr(questions)\n",
        "\n",
        "\n",
        "    # Save Structured Outputs\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # JSON\n",
        "    json_path = f\"{BASE_OUT}/evaluation_results_{timestamp}.json\"\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump({\n",
        "            \"summary\": metrics_summary,\n",
        "            \"ablation\": ablation,\n",
        "            \"details\": evaluation_cache\n",
        "        }, f, indent=2)\n",
        "\n",
        "    # CSV\n",
        "    df = pd.DataFrame([\n",
        "        {\n",
        "            \"Question\": q[\"question\"],\n",
        "            \"Ground_Truth_URL\": q[\"ground_truth_url\"],\n",
        "            \"Answer\": q[\"answer\"],\n",
        "            \"Faithfulness\": m_faithfulness_score(q[\"answer\"], q[\"contexts\"])\n",
        "        }\n",
        "        for q in evaluation_cache\n",
        "    ])\n",
        "    csv_path = f\"{BASE_OUT}/evaluation_results_{timestamp}.csv\"\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    # HTML Report\n",
        "    html_path = f\"{BASE_OUT}/evaluation_report_{timestamp}.html\"\n",
        "    with open(html_path, \"w\") as f:\n",
        "        f.write(f\"\"\"\n",
        "        <html>\n",
        "        <head><title>Hybrid RAG Evaluation Report</title></head>\n",
        "        <body>\n",
        "        <h1>Hybrid RAG Evaluation Report</h1>\n",
        "        <h2>Summary Metrics</h2>\n",
        "        <pre>{json.dumps(metrics_summary, indent=2)}</pre>\n",
        "\n",
        "        <h2>Ablation Study (MRR)</h2>\n",
        "        <pre>{json.dumps(ablation, indent=2)}</pre>\n",
        "\n",
        "        <h2>Sample Results</h2>\n",
        "        {df.head(10).to_html(index=False)}\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\")\n",
        "\n",
        "    end_time = datetime.now()\n",
        "\n",
        "    print(\"✅ Evaluation Completed\")\n",
        "    print(\"⏱ Total Time:\", end_time - start_time)\n",
        "    print(\"📄 JSON:\", json_path)\n",
        "    print(\"📄 CSV :\", csv_path)\n",
        "    print(\"📄 HTML:\", html_path)\n",
        "\n",
        "    return metrics_summary, ablation\n"
      ],
      "metadata": {
        "id": "5ae3WOc4qYtj"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_summary[\"ablation\"] = ablation_results\n",
        "metrics_summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bjyXwoSJz6QU",
        "outputId": "add75ae6-8ab5-49c8-e997-1eb27950d4a6"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MRR_URL': 0.7275,\n",
              " 'Recall@5': 0.86,\n",
              " 'Avg_Faithfulness': 0.9425,\n",
              " 'ablation': {'dense': 0.7499, 'sparse': 0.6987, 'hybrid': 0.7578}}"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the Pipeline"
      ],
      "metadata": {
        "id": "IbxTSNKsqr6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_summary, ablation_results = run_full_evaluation_pipeline(questions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1vTcqRqEqs3H",
        "outputId": "a60e12ca-b012-4e02-fb24-fb2ad1c4af9f"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Starting Automated Evaluation Pipeline\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running RAG:   0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:   1%|          | 1/100 [00:25<42:33, 25.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:   2%|▏         | 2/100 [00:54<44:37, 27.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:   3%|▎         | 3/100 [01:14<39:02, 24.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:   4%|▍         | 4/100 [01:43<41:34, 25.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:   5%|▌         | 5/100 [01:59<35:18, 22.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:   6%|▌         | 6/100 [02:16<32:17, 20.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:   7%|▋         | 7/100 [02:27<27:07, 17.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:   8%|▊         | 8/100 [02:53<30:49, 20.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:   9%|▉         | 9/100 [03:16<31:51, 21.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  10%|█         | 10/100 [03:40<33:12, 22.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  11%|█         | 11/100 [04:00<31:46, 21.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  12%|█▏        | 12/100 [04:24<32:24, 22.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  13%|█▎        | 13/100 [04:48<32:44, 22.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  14%|█▍        | 14/100 [05:08<31:29, 21.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  15%|█▌        | 15/100 [05:34<32:46, 23.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  16%|█▌        | 16/100 [06:00<33:29, 23.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  17%|█▋        | 17/100 [06:21<32:06, 23.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  18%|█▊        | 18/100 [06:44<31:43, 23.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  19%|█▉        | 19/100 [07:10<32:12, 23.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  20%|██        | 20/100 [07:32<31:18, 23.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  21%|██        | 21/100 [07:51<28:51, 21.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  22%|██▏       | 22/100 [08:18<30:44, 23.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  23%|██▎       | 23/100 [08:40<29:39, 23.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  24%|██▍       | 24/100 [09:06<30:19, 23.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  25%|██▌       | 25/100 [09:20<26:02, 20.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  26%|██▌       | 26/100 [09:45<27:27, 22.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  27%|██▋       | 27/100 [10:11<28:16, 23.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  28%|██▊       | 28/100 [10:35<28:23, 23.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  29%|██▉       | 29/100 [11:00<28:27, 24.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  30%|███       | 30/100 [11:22<27:18, 23.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  31%|███       | 31/100 [11:46<27:03, 23.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  32%|███▏      | 32/100 [12:03<24:27, 21.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  33%|███▎      | 33/100 [12:29<25:29, 22.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  34%|███▍      | 34/100 [12:55<26:05, 23.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  35%|███▌      | 35/100 [13:12<23:28, 21.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  36%|███▌      | 36/100 [13:37<24:16, 22.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  37%|███▋      | 37/100 [14:02<24:47, 23.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  38%|███▊      | 38/100 [14:27<24:42, 23.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  39%|███▉      | 39/100 [14:43<21:46, 21.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  40%|████      | 40/100 [15:02<20:39, 20.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  41%|████      | 41/100 [15:21<19:49, 20.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  42%|████▏     | 42/100 [15:46<20:56, 21.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  43%|████▎     | 43/100 [16:11<21:28, 22.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  44%|████▍     | 44/100 [16:36<21:47, 23.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  45%|████▌     | 45/100 [17:01<21:52, 23.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  46%|████▌     | 46/100 [17:20<20:16, 22.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  47%|████▋     | 47/100 [17:46<20:41, 23.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  48%|████▊     | 48/100 [18:11<20:53, 24.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  49%|████▉     | 49/100 [18:24<17:37, 20.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  50%|█████     | 50/100 [18:43<16:46, 20.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  51%|█████     | 51/100 [19:07<17:20, 21.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  52%|█████▏    | 52/100 [19:29<17:13, 21.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  53%|█████▎    | 53/100 [19:46<15:45, 20.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  54%|█████▍    | 54/100 [20:11<16:31, 21.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  55%|█████▌    | 55/100 [20:33<16:20, 21.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  56%|█████▌    | 56/100 [20:59<16:57, 23.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  57%|█████▋    | 57/100 [21:24<16:58, 23.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  58%|█████▊    | 58/100 [21:51<17:18, 24.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  59%|█████▉    | 59/100 [22:16<16:50, 24.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  60%|██████    | 60/100 [22:41<16:29, 24.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  61%|██████    | 61/100 [23:02<15:22, 23.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  62%|██████▏   | 62/100 [23:14<12:47, 20.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  63%|██████▎   | 63/100 [23:36<12:41, 20.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  64%|██████▍   | 64/100 [24:00<13:00, 21.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  65%|██████▌   | 65/100 [24:21<12:28, 21.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  66%|██████▌   | 66/100 [24:43<12:22, 21.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  67%|██████▋   | 67/100 [25:00<11:08, 20.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  68%|██████▊   | 68/100 [25:25<11:31, 21.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  69%|██████▉   | 69/100 [25:49<11:37, 22.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  70%|███████   | 70/100 [26:16<11:56, 23.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  71%|███████   | 71/100 [26:41<11:37, 24.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  72%|███████▏  | 72/100 [26:57<10:04, 21.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  73%|███████▎  | 73/100 [27:22<10:13, 22.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  74%|███████▍  | 74/100 [27:48<10:12, 23.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  75%|███████▌  | 75/100 [28:13<10:05, 24.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  76%|███████▌  | 76/100 [28:26<08:20, 20.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  77%|███████▋  | 77/100 [28:43<07:30, 19.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  78%|███████▊  | 78/100 [29:08<07:44, 21.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  79%|███████▉  | 79/100 [29:27<07:12, 20.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  80%|████████  | 80/100 [29:49<07:03, 21.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  81%|████████  | 81/100 [30:05<06:08, 19.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  82%|████████▏ | 82/100 [30:31<06:23, 21.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  83%|████████▎ | 83/100 [30:52<06:01, 21.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  84%|████████▍ | 84/100 [31:09<05:20, 20.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  85%|████████▌ | 85/100 [31:29<05:01, 20.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  86%|████████▌ | 86/100 [31:50<04:46, 20.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  87%|████████▋ | 87/100 [32:07<04:09, 19.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  88%|████████▊ | 88/100 [32:30<04:04, 20.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  89%|████████▉ | 89/100 [32:55<03:58, 21.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  90%|█████████ | 90/100 [33:14<03:30, 21.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  91%|█████████ | 91/100 [33:36<03:12, 21.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  92%|█████████▏| 92/100 [34:02<03:01, 22.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  93%|█████████▎| 93/100 [34:25<02:39, 22.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  94%|█████████▍| 94/100 [34:51<02:21, 23.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  95%|█████████▌| 95/100 [35:16<02:00, 24.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  96%|█████████▌| 96/100 [35:42<01:38, 24.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  97%|█████████▋| 97/100 [35:58<01:06, 22.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  98%|█████████▊| 98/100 [36:17<00:42, 21.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG:  99%|█████████▉| 99/100 [36:44<00:22, 22.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Running RAG: 100%|██████████| 100/100 [36:58<00:00, 22.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Evaluation Completed\n",
            "⏱ Total Time: 0:37:02.450421\n",
            "📄 JSON: /content/drive/MyDrive/hybrid_rag/evaluation_outputs/evaluation_results_20260207_163053.json\n",
            "📄 CSV : /content/drive/MyDrive/hybrid_rag/evaluation_outputs/evaluation_results_20260207_163053.csv\n",
            "📄 HTML: /content/drive/MyDrive/hybrid_rag/evaluation_outputs/evaluation_report_20260207_163053.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automated Evaluation Pipeline\n",
        "\n",
        "A single-command automated evaluation pipeline was implemented to load questions, execute the full Hybrid RAG system, compute all evaluation metrics, and generate structured reports. The pipeline produces JSON and CSV files for quantitative analysis and an HTML report for qualitative inspection, ensuring reproducibility and scalability of evaluation.\n"
      ],
      "metadata": {
        "id": "fpDWceQUqz1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5 Evaluation Report Contents"
      ],
      "metadata": {
        "id": "H4-mHH7ayPd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "-k7eJO70yUCX"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REPORT_DIR = \"/content/drive/MyDrive/hybrid_rag/final_report_assets\"\n",
        "os.makedirs(REPORT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "JFQpE-CwyVwx"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Results Table"
      ],
      "metadata": {
        "id": "lcSveQPcyZSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "\n",
        "for i, item in enumerate(evaluation_cache):\n",
        "    ranked_urls = get_ranked_urls_from_rrf(item[\"contexts\"])\n",
        "\n",
        "    rr = reciprocal_rank(ranked_urls, item[\"ground_truth_url\"])\n",
        "    recall = 1 if item[\"ground_truth_url\"] in ranked_urls[:5] else 0\n",
        "    faith = m_faithfulness_score(item[\"answer\"], item[\"contexts\"])\n",
        "\n",
        "    rows.append({\n",
        "        \"Question_ID\": f\"Q{i+1}\",\n",
        "        \"Question\": item[\"question\"],\n",
        "        \"Ground_Truth_URL\": item[\"ground_truth_url\"],\n",
        "        \"Generated_Answer\": item[\"answer\"],\n",
        "        \"MRR\": rr,\n",
        "        \"Recall@5\": recall,\n",
        "        \"Faithfulness\": faith\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(rows)\n",
        "\n",
        "csv_path = f\"{REPORT_DIR}/results_table.csv\"\n",
        "results_df.to_csv(csv_path, index=False)\n",
        "\n",
        "results_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "FLQHpcETyZ8L",
        "outputId": "bc5ca0fa-a5e7-4ea5-e42d-e5f92b1aa7cd"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Question_ID                                           Question  \\\n",
              "0          Q1  How does Directed information differ from Caps...   \n",
              "1          Q2                                   Explain LRE Map.   \n",
              "2          Q3    Why is Causes of gender incongruence important?   \n",
              "\n",
              "                                    Ground_Truth_URL  \\\n",
              "0  https://en.wikipedia.org/wiki/Directed_informa...   \n",
              "1              https://en.wikipedia.org/wiki/LRE_Map   \n",
              "2  https://en.wikipedia.org/wiki/Causes_of_gender...   \n",
              "\n",
              "                                    Generated_Answer  MRR  Recall@5  \\\n",
              "0  [INST]\\nYou are an assistant that answers ques...  0.0         0   \n",
              "1  [INST]\\nYou are an assistant that answers ques...  1.0         1   \n",
              "2  [INST]\\nYou are an assistant that answers ques...  1.0         1   \n",
              "\n",
              "   Faithfulness  \n",
              "0         0.940  \n",
              "1         0.945  \n",
              "2         0.946  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62c91883-04be-43c0-b87b-7a9f48a1357e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question_ID</th>\n",
              "      <th>Question</th>\n",
              "      <th>Ground_Truth_URL</th>\n",
              "      <th>Generated_Answer</th>\n",
              "      <th>MRR</th>\n",
              "      <th>Recall@5</th>\n",
              "      <th>Faithfulness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>How does Directed information differ from Caps...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Directed_informa...</td>\n",
              "      <td>[INST]\\nYou are an assistant that answers ques...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q2</td>\n",
              "      <td>Explain LRE Map.</td>\n",
              "      <td>https://en.wikipedia.org/wiki/LRE_Map</td>\n",
              "      <td>[INST]\\nYou are an assistant that answers ques...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q3</td>\n",
              "      <td>Why is Causes of gender incongruence important?</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Causes_of_gender...</td>\n",
              "      <td>[INST]\\nYou are an assistant that answers ques...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62c91883-04be-43c0-b87b-7a9f48a1357e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62c91883-04be-43c0-b87b-7a9f48a1357e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62c91883-04be-43c0-b87b-7a9f48a1357e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Question_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Q1\",\n          \"Q2\",\n          \"Q3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"How does Directed information differ from Capsule neural network?\",\n          \"Explain LRE Map.\",\n          \"Why is Causes of gender incongruence important?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ground_Truth_URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"https://en.wikipedia.org/wiki/Directed_information\",\n          \"https://en.wikipedia.org/wiki/LRE_Map\",\n          \"https://en.wikipedia.org/wiki/Causes_of_gender_incongruence\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Generated_Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[INST]\\nYou are an assistant that answers questions strictly using the provided context.\\n\\nIf the context contains partial information, synthesize the best possible answer.\\nIf the answer is completely missing, reply with \\\"I don't know\\\".\\n\\nContext:\\n[Context 1]\\nfeatures . A single weight matrix is used by each capsule across all receptive fields . Each primary capsule sees all of the lower-layer outputs whose fields overlap with the center of the field in the primary layer . Each primary capsule output is an 8-dimensional vector . A second , digit capsule layer has one 16-dimensional capsule for each digit . Dynamic routing connects primary and digit capsule layers . A [ 32x6x6 ] x 10 weight matrix controls the mapping between layers . Capsnets are hierarchical , in that each lower-level capsule contributes significantly to only one higher-level capsule . However , replicating learned knowledge remains valuable . To achieve this , a capsnet 's lower layers are convolutional , including hidden capsule layers . Higher layers thus cover larger regions , while retaining information about the precise position of each object within the region . For low level capsules , location information is `` place-coded '' according to which capsule is active . Higher up , more and more of the positional information is rate-coded in the capsule 's output vector . This shift from place-coding to rate-coding , combined with the fact that higher-level capsules represent more complex objects with more degrees of freedom , suggests that capsule dimensionality increases with level . Human vision Human vision examines a sequence of focal points , processing only a fraction of the scene at its highest resolution . Capsnets build on inspirations from cortical minicolumns in the cerebral cortex . A minicolumn is a structure containing 80-120 neurons , with a diameter of about 28-40 \\u03bcm , spanning all layers in the cerebral cortex . All neurons in the larger minicolumns have the same receptive field , and they output their activations as action potentials or spikes . Neurons within the microcolumn receive common inputs , have common outputs , are interconnected and may constitute a fundamental computational unit of the cerebral cortex . Capsnets explore the intuition that the human visual system creates a tree-like structure for each focal point and coordinates these trees to recognize objects . However , with capsnets each tree is `` carved '' from a fixed network rather than assembled on the fly . Alternatives CapsNets are claimed to have four major conceptual advantages over convolutional neural networks : Viewpoint invariance : the use of pose matrices allows capsule networks to recognize\\n\\n[Context 2]\\nA capsule neural network is a machine learning system that is a type of artificial neural network that can be used to better model hierarchical relationships . The approach is an attempt to more closely mimic biological neural organization . The idea is to add structures called `` capsules '' to a convolutional neural network , and to reuse output from several of those capsules to form more stable representations for higher capsules . The output is a vector consisting of the probability of an observation , and a pose for that observation . This vector is similar to what is done for example when doing classification with localization in CNNs . Among other benefits , capsnets address the `` Picasso problem '' in image recognition : images that have all the right parts but that are not in the correct spatial relationship . For image recognition , capsnets exploit the fact that while viewpoint changes have nonlinear effects at the pixel level , they have linear effects at the part/object level . This can be compared to inverting the rendering of an object of multiple parts . History In 2000 , Geoffrey Hinton et al . described an imaging system that combined segmentation and recognition into a single inference process using parse trees . So-called credibility networks described the joint distribution over the latent variables and over the possible parse trees . That system proved useful on the MNIST handwritten digit database . A dynamic routing mechanism for capsule networks was introduced by Hinton and his team in 2017 . The approach was claimed to reduce error rates on MNIST and to reduce training set sizes . Results were claimed to be considerably better than a CNN on highly overlapped digits . In Hinton 's original idea one minicolumn would represent and detect one multidimensional entity . Transformations An invariant is an object property that does not change as a result of some transformation . For example , the area of a circle does not change if the circle is shifted to the left . Informally , an equivariant is a property that changes predictably under transformation . For example , the center of a circle moves by the same amount as the circle when shifted . A nonequivariant is a property whose value does not change predictably under a transformation . For example , transforming a circle into\\n\\n[Context 3]\\ncoupling coefficients and the hidden prediction matrix are shown . The structure in layer I and II is somewhat similar to the cerebral cortex if stellate cells are assumed to be involved in transposing input vectors . Whether both types of stellate cells have the same function is not clear , as layer I has excitatory spiny cells and layer II has inhibitory aspiny cells . The latter indicates a much different network . At line 10 , the squash function can be replaced by other functions and network topologies that retain the vector direction . The procedure conducts r { \\\\textstyle r } iterations , usually 4\\u20135 , with l { \\\\textstyle l } the index for the source capsule layer or primary layer , where the routing goes from , and the capsule layer l + 1 { \\\\textstyle l+1 } the next higher layer . Training Learning is supervised . The network is trained by minimizing the euclidean distance between the image and the output of a CNN that reconstructs the input from the output of the terminal capsules . The network is discriminatively trained , using iterative routing-by-agreement . The activity vectors of all but the correct parent are masked . Margin loss The length of the instantiation vector represents the probability that a capsule 's entity is present in the scene . A top-level capsule has a long vector if and only if its associated entity is present . To allow for multiple entities , a separate margin loss is computed for each capsule . Downweighting the loss for absent entities stops the learning from shrinking activity vector lengths for all entities . The total loss is the sum of the losses of all entities . In Hinton 's example the loss function is : L k = T k max 2 \\u23df class present + \\u03bb max 2 \\u23df class not present , T k = { 1 , digit of class k present 0 , otherwise { \\\\displaystyle { \\\\begin { aligned } L_ { k } & =\\\\underbrace { T_ { k } ~ { \\\\max \\\\left } ^ { 2 } } _ { \\\\mbox { class present } } +\\\\underbrace { \\\\lambda \\\\left~ { \\\\max \\\\left } ^ { 2 } } _ { \\\\mbox { class not present } } , & T_ { k } = { \\\\begin\\n\\n[Context 4]\\n. However , with capsnets each tree is `` carved '' from a fixed network rather than assembled on the fly . Alternatives CapsNets are claimed to have four major conceptual advantages over convolutional neural networks : Viewpoint invariance : the use of pose matrices allows capsule networks to recognize objects regardless of the perspective from which they are viewed . Fewer parameters : Because capsules group neurons , the connections between layers require fewer parameters . Better generalization to new viewpoints : CNNs , when trained to understand rotations , often learn that an object can be viewed similarly from several different rotations . However , capsule networks generalize better to new viewpoints because pose matrices can capture these characteristics as linear transformations . Defense against white-box adversarial attacks : the Fast Gradient Sign Method is a typical method for attacking CNNs . It evaluates the gradient of each pixel against the loss of the network , and changes each pixel by at most epsilon to maximize the loss . Although this method can drop the accuracy of CNNs dramatically , capsule networks maintain accuracy above 70 % . Purely convolutional nets can not generalize to unlearned viewpoints . For other affine transformations , either feature detectors must be repeated on a grid that grows exponentially with the number of transformation dimensions , or the size of the labelled training set must expand to encompass those viewpoints . These exponential explosions make them unsuitable for larger problems . Capsnet 's transformation matrices learn the spatial relationship between a part and a whole , allowing the latter to be recognized based on such relationships . However , capsnets assume that each location displays at most one instance of a capsule 's object . This assumption allows a capsule to use a distributed representation of an object to represent that object at that location . Capsnets use neural activities that vary with viewpoint . They do not have to normalize objects and can even recognize multiply transformed objects . Capsnets can also process segmented objects . Hybridization There are some suggestions for hybrid approaches by Capsule Networks . See also Convolutional neural network Geoffrey Hinton MNIST database Notes References External links Capsules Network Implementation in PyTorch , fixing several bugs in previous implementations , 2018-04-16 , retrieved 2018-04-16 Pytorch code : Capsule Routing via Variational Bayes , February 2020 , retrieved\\n\\n[Context 5]\\na higher-capsule decided by a dynamic process routine . CapsE : CapsE implements a capsule network to model a fact { \\\\displaystyle } . As in ConvKB , each triple element is concatenated to build a matrix [ h ; r ; t ] { \\\\displaystyle { \\\\ce { [ h ; { \\\\mathcal { r } } ; t ] } } } and is used to feed to a convolutional layer to extract the convolutional features . These features are then redirected to a capsule to produce a continuous vector , more the vector is long , more the fact is true . Recurrent neural networks This class of models leverages the use of recurrent neural network . The advantage of this architecture is to memorize a sequence of fact , rather than just elaborate single events . RSN : During the embedding procedure is commonly assumed that , similar entities has similar relations . In practice , this type of information is not leveraged , because the embedding is computed just on the undergoing fact rather than a history of facts . Recurrent skipping networks uses a recurrent neural network to learn relational path using a random walk sampling . Model performance The machine learning task for knowledge graph embedding that is more often used to evaluate the embedding accuracy of the models is the link prediction . Rossi et al . produced an extensive benchmark of the models , but also other surveys produces similar results . The benchmark involves five datasets FB15k , WN18 , FB15k-237 , WN18RR , and YAGO3-10 . More recently , it has been discussed that these datasets are far away from real-world applications , and other datasets should be integrated as a standard benchmark . Libraries KGE on GitHub MEI-KGE on GitHub Pykg2vec on GitHub DGL-KE on GitHub PyKEEN on GitHub TorchKGE on GitHub AmpliGraph on GitHub OpenKE on GitHub scikit-kge on GitHub Fast-TransX on GitHub MEIM-KGE on GitHub DICEE on GitHub See also Knowledge graph Embedding Machine learning Knowledge base Knowledge extraction Statistical relational learning Representation learning Graph embedding References External links Open Graph Benchmark - Stanford WordNet - Princeton\\n\\nQuestion:\\nHow does Directed information differ from Capsule neural network?\\n[/INST] Directed information and Capsule neural networks are different concepts in the field of machine learning and neural networks.\\n\\nDirected information is a measure of the amount of information that a random variable X conveys about a random variable Y, taking into account the causal relationship between them. It is a measure of the dependence of Y on X, and is used to quantify the flow of information from one variable to another.\\n\\nCapsule neural networks, on the other hand, are a type of neural network that are designed to better model hierarchical relationships and recognize objects regardless of their perspective. They use capsules, which are groups of neurons that learn to represent the presence and properties of an object, and dynamic routing to refine the representations of higher-level capsules based on the outputs of lower-level capsules. The output of a capsule is a vector consisting of the probability of the presence of the object and its pose information.\\n\\nWhile both\",\n          \"[INST]\\nYou are an assistant that answers questions strictly using the provided context.\\n\\nIf the context contains partial information, synthesize the best possible answer.\\nIf the answer is completely missing, reply with \\\"I don't know\\\".\\n\\nContext:\\n[Context 1]\\nThe LRE Map is a freely accessible large database on resources dedicated to Natural language processing . The original feature of LRE Map is that the records are collected during the submission of different major Natural language processing conferences . The records are then cleaned and gathered into a global database called `` LRE Map '' . The LRE Map is intended to be an instrument for collecting information about language resources and to become , at the same time , a community for users , a place to share and discover resources , discuss opinions , provide feedback , discover new trends , etc . It is an instrument for discovering , searching and documenting language resources , here intended in a broad sense , as both data and tools . The large amount of information contained in the Map can be analyzed in many different ways . For instance , the LRE Map can provide information about the most frequent type of resource , the most represented language , the applications for which resources are used or are being developed , the proportion of new resources vs. already existing ones , or the way in which resources are distributed to the community . Context Several institutions worldwide maintain catalogues of language resources However , it has been estimated that only 10 % of existing resources are known , either through distribution catalogues or via direct publicity by providers . The rest remains hidden , the only occasions where it briefly emerges being when a resource is presented in the context of a research paper or report at some conference . Even in this case , nevertheless , it might be that a resource remains in the background simply because the focus of the research is not on the resource per se . History The LRE Map originated under the name `` LREC Map '' during the preparation of LREC 2010 conference . More specifically , the idea was discussed within the FlaReNet project , and in collaboration with ELRA and the Institute of Computational Linguistics of CNR in Pisa , the Map was put in place at LREC 2010 . The LREC organizers asked the authors to provide some basic information about all the resources , either used or created , described in their papers . All these descriptors were then gathered in a global matrix called the\\n\\n[Context 2]\\nPisa , the Map was put in place at LREC 2010 . The LREC organizers asked the authors to provide some basic information about all the resources , either used or created , described in their papers . All these descriptors were then gathered in a global matrix called the LREC Map . The same methodology and requirements from the authors has been then applied and extended to other conferences , namely COLING-2010 , EMNLP-2010 , RANLP-2011 , LREC 2012 , LREC 2014 and LREC 2016 . After this generalization to other conferences , the LREC Map has been renamed as the LRE Map . Size and content The size of the database increases over time . The data collected amount to 4776 entries . Each resource is described according to the following attributes : Resource type , e.g . lexicon , annotation tool , tagger/parser . Resource production status , e.g . newly created finished , existing-updated . Resource availability , e.g . freely available , from data center . Resource modality , e.g . speech , written , sign language . Resource use , e.g . named entity recognition , language identification , machine translation . Resource language , e.g . English , 23 European Union languages , official languages of India . Uses The LRE map is a very important tool to chart the NLP field . Compared to other studied based on subjective scorings , the LRE map is made of real facts . The map has a great potential for many uses , in addition to being an information gathering tool : It is a great instrument for monitoring the evolution of the field , if applied in different contexts and times . It can be seen as a huge joint effort , the beginning of an even larger cooperative action not just among few leaders but among all the researchers . It is also an `` educational '' means towards the broad acknowledgment of the need of meta-research activities with the active involvement of many . It is also instrumental in introducing the new notion of `` citation of resources '' that could provide an award and a means of scholarly recognition for researchers engaged in resource creation . It is used to help the organization of the conferences of the field like LREC . Derived matrices The data were then cleaned and sorted\\n\\n[Context 3]\\nThe International Conference on Language Resources and Evaluation is an international conference organised by the ELRA Language Resources Association every other year with the support of institutions and organisations involved in Natural language processing . The series of LREC conferences was launched in Granada in 1998 . History of conferences The survey of the LREC conferences over the period 1998-2013 was presented during the 2014 conference in Reykjavik as a closing session . It appears that the number of papers and signatures is increasing over time . The average number of authors per paper is higher as well . The percentage of new authors is between 68 % and 78 % . The distribution between male and female authors is stable over time . The most frequent technical term is `` annotation '' , then comes `` part-of-speech '' . The LRE Map The LRE Map was introduced at LREC 2010 and is now a regular feature of the LREC submission process for both the conference papers and the workshop papers . At the submission stage , the authors are asked to provide some basic information about all the resources , either used or created , described in their papers . All these descriptors are then gathered in a global matrix called the LRE Map . This feature has been extended to several other conferences . References External links Conference website European Language Resources Association web site\\n\\n[Context 4]\\nA self-organizing map or self-organizing feature map is an unsupervised machine learning technique used to produce a low-dimensional representation of a higher-dimensional data set while preserving the topological structure of the data . For example , a data set with p { \\\\displaystyle p } variables measured in n { \\\\displaystyle n } observations could be represented as clusters of observations with similar values for the variables . These clusters then could be visualized as a two-dimensional `` map '' such that observations in proximal clusters have more similar values than observations in distal clusters . This can make high-dimensional data easier to visualize and analyze . An SOM is a type of artificial neural network but is trained using competitive learning rather than the error-correction learning used by other artificial neural networks . The SOM was introduced by the Finnish professor Teuvo Kohonen in the 1980s and therefore is sometimes called a Kohonen map or Kohonen network . The Kohonen map or network is a computationally convenient abstraction building on biological models of neural systems from the 1970s and morphogenesis models dating back to Alan Turing in the 1950s . SOMs create internal representations reminiscent of the cortical homunculus , a distorted representation of the human body , based on a neurological `` map '' of the areas and proportions of the human brain dedicated to processing sensory functions , for different parts of the body . Overview Self-organizing maps , like most artificial neural networks , operate in two modes : training and mapping . First , training uses an input data set to generate a lower-dimensional representation of the input data . Second , mapping classifies additional input data using the generated map . In most cases , the goal of training is to represent an input space with p dimensions as a map space with two dimensions . Specifically , an input space with p variables is said to have p dimensions . A map space consists of components called `` nodes '' or `` neurons '' , which are arranged as a hexagonal or rectangular grid with two dimensions . The number of nodes and their arrangement are specified beforehand based on the larger goals of the analysis and exploration of the data . Each node in the map space is associated with a `` weight '' vector , which is the position of the\\n\\n[Context 5]\\nas the linear sum of the GAP values , weights and bias : y C = \\u2211 k w k C F k { \\\\displaystyle y^ { C } =\\\\sum _ { k } w_ { k } ^ { C } F^ { k } } The localization map is computed as follows : L C A M C = R e L U ( \\u2211 k w k C A k ) { \\\\displaystyle L_ { CAM } ^ { C } =ReLU ( \\\\sum _ { k } w_ { k } ^ { C } A_ { k } ) } namely , A k { \\\\displaystyle A_ { k } } is the activation of node k in the target layer of the model , and w k C { \\\\displaystyle w_ { k } ^ { C } } is the class-specific weight , for the channel k , in the linear classifier layer . Advantages and drawbacks The use of the GAP layer represents an example of an interpretability by design approach . IBD refers to a technique which uses the model 's own architecture to help explain its predictions . The main drawback of CAM is that it is highly model-specific , being applicable to CNN architectures whose layer before the softmax one is a GAP . Since the approach relies on the post-GAP weights for the overall evaluation , the method ca n't be applied to intermediate layers . The choice of dealing with an IBD approach restricts the possibility to generalize the model architecture . Moreover , IBD methods often require re-training of the model . Gradient-weighted class activation mapping Gradient-weighted class activation mapping is a generalized version of CAM and it tackles its architectural limitations . Grad-CAM computes the gradient of a target class score , the pre-softmax logit , with respect to the feature maps of a convolutional neural network . The gradients are global-average-pooled to obtain importance weights , which are used to compute a class-specific localization map by linearly weighting the feature maps . The result is a heatmap that highlights the regions in the input image that are the most influential for predicting the target class . The main advantage of Grad-CAM , with respect to the standard CAM , is that it is model agnostic , meaning that it generates visual explanation for any\\n\\nQuestion:\\nExplain LRE Map.\\n[/INST] The LRE Map is a large database on language resources in the field of Natural Language Processing (NLP). It was initiated at the LREC 2010 conference and has since been expanded to include data from other conferences such as COLING-2010, EMNLP-2010, RANLP-2011, LREC 2012, and LREC 2014. The LRE Map collects basic information about resources, either used or created, described in papers submitted to these conferences. Each resource is described according to attributes such as resource type, production status, availability, modality, and use. The LRE Map is a valuable tool for charting the evolution of the NLP field, monitoring its progress, and introducing the concept of citation of resources for scholarly recognition. The data is gathered in a global matrix called the LRE Map.\",\n          \"[INST]\\nYou are an assistant that answers questions strictly using the provided context.\\n\\nIf the context contains partial information, synthesize the best possible answer.\\nIf the answer is completely missing, reply with \\\"I don't know\\\".\\n\\nContext:\\n[Context 1]\\nGender incongruence is the state of having a gender identity that does not correspond to one 's sex assigned at birth . This is experienced by people who identify as transgender or transsexual , and often results in gender dysphoria . The causes of gender incongruence have been studied for decades . Transgender brain studies , especially those on trans women attracted to women , and those on trans men attracted to men , are limited , as they include only a small number of tested individuals . Twin studies indicate that genes play a role in gender incongruence , although the precise genes involved are not known or well understood . Environmental factors , such as prenatal hormone exposure , have also been investigated but are difficult to test . Genetics Gender identity is genetically heritable , but no convincing candidate genes are known . Gender incongruence has been associated with certain alleles relevant to steroidogenesis . In 2013 , a twin study combined a survey of pairs of twins where one or both had undergone , or had plans and medical approval to undergo , gender transition , with a literature review of published reports of transgender twins . The study found that one third of identical twin pairs in the sample were both transgender : 13 of 39 monozygotic or identical pairs of assigned males and 8 of 35 pairs of assigned females . Among dizygotic or genetically non-identical twin pairs , there was only 1 of 38 pairs where both twins were trans . The significant percentage of identical twin pairs in which both twins are trans and the virtual absence of dizygotic twins in which both were trans would provide evidence that transgender identity is significantly influenced by genetics if both sets were raised in different families . A 2018 review of family and twin studies found that there was `` significant and consistent evidence '' for gender identity being genetically heritable . Prenatal hormonal environment Sex hormones in the prenatal environment differentiate the male and female brain . One hypothesis proposes that transgender individuals may have been exposed to atypical levels of sex hormones during later stages of fetal development , leading to brain structures atypical of their sex assigned at birth . In people with XX chromosomes , congenital adrenal hyperplasia results in heightened exposure to prenatal androgens , resulting in masculinization of\\n\\n[Context 2]\\nNeurosexism is an alleged bias in the neuroscience of sex differences towards reinforcing harmful gender stereotypes . The term was coined by feminist scholar Cordelia Fine in a 2008 article and popularised by her 2010 book Delusions of Gender . The concept is now widely used by critics of the neuroscience of sex differences in neuroscience , neuroethics and philosophy . Definition Neuroscientist Gina Rippon defines neurosexism as follows : `` 'Neurosexism ' is the practice of claiming that there are fixed differences between female and male brains , which can explain women 's inferiority or unsuitability for certain roles . '' For example , `` this includes things such as men being more logical and women being better at languages or nurturing . '' Fine and Rippon , along with Daphna Joel , state that `` the point of critical enquiry is not to deny differences between the sexes , but to ensure a full understanding of the findings and meaning of any particular report . '' Many of the issues they discuss to support their position are `` serious issues for all areas of behavioral research '' , but they argue that `` in sex/gender differences research ... they are often particularly acute . '' Nonetheless , the common factor influencing logical maturity between males and females is the maturity of the frontal cortex , which matures at the age of 25 , at the earliest . The topic of neurosexism is thus closely tied to wider debates about scientific methodology , especially in the behavioral sciences . History The history of science contains many examples of scientists and philosophers drawing conclusions about the mental inferiority of women , or their lack of aptitude for certain tasks , on the basis of alleged anatomical differences between male and female brains . In the late 19th century , George J. Romanes used the difference in average brain weight between men and women to explain the `` marked inferiority of intellectual power '' of the latter . Absent a sexist background assumption about male superiority , there would be nothing to explain here . Despite these historical pseudo-scientific studies , Becker et al . argue that `` for decades '' the scientific community has abstained from studying sex-differences . Larry Cahill asserts that today there is a widely held belief in the scientific community that sex-differences do not matter to\\n\\n[Context 3]\\ndomain of science , raising further concerns for the feminist camp for whilst we can apply the necessary checks and balances in the method of our science , once the information is in the public consciousness they can manipulate and construe research however they see fit . Communication and neurological discoveries The interest and coverage generated by neurological studies on sex differences is an instance of a wider phenomenon . It is possible to see the 'neuro- ' prefix being widely used : `` neuromarketing '' , `` neuroeconomics '' , `` neurodrinks '' . One study documented in the Journal of Cognitive Neuroscience tested the hypothesis that irrelevant neuroscience explanations accompanying descriptions of psychological phenomena causes people to rate the descriptions as better quality . Results showed that irrelevant neuroscience information does indeed cause people to rate explanations more satisfying than without , even in cases where neuroscience was not useful to explain the phenomenon . Methodological issues According to Cordelia Fine and Gina Rippon , there are systematic methodological issues in the neuroscience of sex differences that increase the chances of neurosexism . In other words , questions of neurosexism are not entirely independent of questions about scientific methodology . Reverse inferences A reverse inference infers that activation in a particular brain region causes the presence of a mental process . Fine argues that such inferences are routine in the neuroscience of sex differences , yet `` the absence of neat one-to-one mapping between brain regions and mental processes renders reverse inferences logically invalid '' . She emphasises that mental processes arise from complex interactions between a multiplicity of brain regions ; the inference from correlation to causation is invalid , because the interactions between brain regions and mental processes are vastly complex . The invalidity stems from brain region activation being multiply realisable . For example , the mental processes of experiencing visual art and experiencing the taste of food both activate the nucleus accumbens ; activation of the nucleus accumbens then does n't necessarily cause the mental process of tasting food , since activation could be causing another mental process . Plasticity Plasticity refers to the brain 's ability to change as a result of experiences in one 's life . Because of the brain 's plasticity , it is possible in principle for social phenomena related to gender to influence the organization of a person\\n\\n[Context 4]\\ntrans women had undergone hormone therapy , and all but one had undergone sex reassignment surgery , this was accounted for by including cadavers of cisgender men and cisgender women as controls who , for a variety of medical reasons , had experienced hormone reversal . The controls still had sizes typical for their sex , and thus no relationship to post-natal hormone levels was found . Other post-mortem studies also found brain differences between cisgender and transgender individuals . In 2002 , a follow-up study by Chung et al . found that significant sexual dimorphism in BSTc did not establish until adulthood . Chung et al . theorized that changes in fetal hormone levels produce changes in BSTc synaptic density , neuronal activity , or neurochemical content which later lead to size and neuron count changes in BSTc , or alternatively , that the size of BSTc is affected by the generation of a gender identity inconsistent with one 's assigned sex . In the textbook Adult Psychopathology and Diagnosis , 7th edition , Lawrence and Zucker suggested that the BSTc may not be a valid biomarker for gender incongruence , as differences in size could be caused by gender-affirming hormone therapy or paraphilias , and might not occur in homosexual transsexuals . In a review of the evidence in 2006 , Gooren considered the earlier research as supporting the concept of gender incongruence as a `` sexual differentiation disorder '' of the sexually dimorphic brain . Dick Swaab concurred . In 2008 , Garcia-Falgueras & Swaab discovered that the interstitial nucleus of the anterior hypothalamus , part of the hypothalamic uncinate nucleus , had properties similar to the BSTc with respect to sexual dimorphism and gender incongruence , likewise in line with the trans individuals \\u2019 declared genders and likewise regardless of if hormonal transition had occurred or not . A 2009 MRI study by Luders et al . found that among 24 trans women not treated with hormone therapy , regional gray matter concentrations were more similar to those of cisgender men than of cisgender women , but there was a significantly greater volume of gray matter in the right putamen compared to cisgender men . Like earlier studies , researchers concluded that transgender identity was associated with a distinct cerebral pattern . MRI scanning allows easier study of larger brain structures , but independent nuclei are\\n\\n[Context 5]\\nright hemisphere . Morphological increments observed in the brains of trans men might be due to the anabolic effects of testosterone . Onset According to the DSM-5 , gender dysphoria in those assigned male at birth tends to follow one of two broad trajectories : early-onset or late-onset . Early-onset gender dysphoria is behaviorally visible in childhood . Sometimes , gender dysphoria may stop for a while in this group , and they may identify as gay or homosexual for a period of time , followed by recurrence of gender dysphoria . This group is usually androphilic in adulthood . Late-onset gender dysphoria does not include visible signs in early childhood , but some report having had wishes to be the opposite sex in childhood that they did not report to others . Trans women who experience late-onset gender dysphoria are more likely be attracted to women and may identify as lesbians or bisexual . It is common for people assigned male at birth who have late-onset gender dysphoria to experience sexual excitement from cross-dressing . In those assigned female at birth , early-onset gender dysphoria is the most common course . This group is usually sexually attracted to women . Trans men who experience late-onset gender dysphoria will usually be sexually attracted to men and may identify as gay . In general , onset of symptoms may begin at any time after an individual reaches the age of two or three . Blanchard 's typology In the 1980s and 1990s , sexologist Ray Blanchard developed a taxonomy of male-to-female transsexualism built upon the work of his colleague Kurt Freund , which argues that trans women have one of two primary causes of gender dysphoria . Blanchard theorized that `` homosexual transsexuals '' are attracted to men and develop gender dysphoria typically during childhood , and characterizes them as displaying overt and obvious femininity since childhood ; he characterizes `` non-homosexual transsexuals '' as developing gender dysphoria primarily due to autogynephilia , and as attracted to women , attracted to both women and men , or asexual . Blanchard 's theory has received support from J. Michael Bailey , Anne Lawrence , and James Cantor . Blanchard argued that there are significant differences between the two groups , including sexuality , age of transition , ethnicity , IQ , fetishism , and quality of adjustment . Blanchard 's typology has\\n\\nQuestion:\\nWhy is Causes of gender incongruence important?\\n[/INST] The causes of gender incongruence are important because they help us understand the biological and environmental factors that contribute to the development of a gender identity that does not correspond to one's sex assigned at birth. This is a significant issue for transgender and transsexual individuals, who may experience gender dysphoria as a result of this incongruence. Understanding the causes of gender incongruence can also help inform the development of more effective treatments and interventions for gender dysphoria, as well as contribute to a greater understanding of human sexual and gender development more broadly. Additionally, research on the causes of gender incongruence can help challenge harmful stereotypes and biases related to gender and neurosexism.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MRR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5773502691896258,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall@5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0032145502536643214,\n        \"min\": 0.94,\n        \"max\": 0.946,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.94,\n          0.945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric Comparison Bar Chart"
      ],
      "metadata": {
        "id": "BCb1b5YtydIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_metrics = {\n",
        "    k: v for k, v in metrics_summary.items()\n",
        "    if isinstance(v, (int, float))\n",
        "}\n",
        "\n",
        "numeric_metrics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JBLZH20Z9JFD",
        "outputId": "20c943db-6265-4a70-e193-2240a0d2cb37"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MRR_URL': 0.7275, 'Recall@5': 0.86, 'Avg_Faithfulness': 0.9425}"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.bar(\n",
        "    numeric_metrics.keys(),\n",
        "    numeric_metrics.values()\n",
        ")\n",
        "plt.title(\"Overall Evaluation Metrics\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0, 1)\n",
        "plt.savefig(f\"{REPORT_DIR}/metrics_summary.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "rZD79GRUydwc",
        "outputId": "143e566e-7532-4f63-cfc9-56dc0bd427bb"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Score Distribution Plots"
      ],
      "metadata": {
        "id": "vRcBT9ctyfTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "results_df[\"MRR\"].hist(bins=20)\n",
        "plt.title(\"MRR Score Distribution\")\n",
        "plt.xlabel(\"MRR\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.savefig(f\"{REPORT_DIR}/mrr_distribution.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "results_df[\"Faithfulness\"].hist(bins=20)\n",
        "plt.title(\"Faithfulness Score Distribution\")\n",
        "plt.xlabel(\"Faithfulness\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.savefig(f\"{REPORT_DIR}/faithfulness_distribution.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "xNTaGAqQyhgW",
        "outputId": "dab7e760-3b39-4031-8e4e-ad3b391bbe74"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ablation Study Visualization"
      ],
      "metadata": {
        "id": "_Pg5yfPiykxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.bar(ablation_results.keys(), ablation_results.values())\n",
        "plt.title(\"Ablation Study (MRR Comparison)\")\n",
        "plt.ylabel(\"MRR\")\n",
        "plt.savefig(f\"{REPORT_DIR}/ablation_mrr.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "UIv25pi7ylYu",
        "outputId": "1e915043-8ada-4fba-bcf9-7fa6219b174c"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGzCAYAAADT4Tb9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPIpJREFUeJzt3XtcVVX+//H3AeWgIKig4IUkNVPU1CAQzbBEsczLTBnZBaS0TJlMujg03xE1JyqVMDMdHS9lmo5lZmmaYdSUpqWZl8z7rRQEU7zkQMH6/dHPM504KpRwcPt6Ph778fCsvdben33cR97uvfbBZowxAgAAsAgPdxcAAABwKRFuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuYCn79++XzWbThAkTLtp39OjRstlsl3T/2dnZstlsys7OvqTbvVzMmTNHNptN+/fvv6Tbve222zR48OBLuk1ULpvNptGjR7u1hmPHjsnHx0fLly93ax2oeIQbXFZeeeUV2Ww2RUVFub2OOXPmuLWG3yopKdFrr72mqKgo1a1bV7Vq1VKLFi2UkJCgzz//3NHvm2++0ejRoy95AKkon332mT744AONHDnS0XYuRNpsNr3++usux3Xu3Fk2m01t2rRxag8NDXWMtdls8vHxUWRkpF577bVS2/j1fmw2mzw9PVW/fn3deeed2r59e7mOY8+ePXr44YfVtGlTeXt7y8/PT507d9akSZN09uzZcm0Lv09AQIAGDRqkv//97+4uBRWsmrsLAMpj3rx5Cg0N1fr167V79241b97cLXW88sorCgwM1MCBA53ab7rpJp09e1ZeXl6VXtOjjz6qKVOmqG/fvrr33ntVrVo17dixQ++//76aNm2qjh07Svol3IwZM0Zdu3ZVaGhopddZXuPHj1e3bt1c/l17e3tr/vz5uu+++5za9+/frzVr1sjb29vlNtu3b6/HH39cknTkyBH961//UmJiogoLC11eIXr00Ud1ww036KefftLmzZs1bdo0ZWdna+vWrQoODr7oMSxbtkz9+/eX3W5XQkKC2rRpo6KiIn366ad68skntW3bNk2fPr0sb8dl6+zZs6pWzf0/coYMGaKXXnpJq1ev1i233OLuclBB3H+mAWW0b98+rVmzRosXL9bDDz+sefPmKS0tzd1lOfHw8DjvD9SKlJubq1deeUWDBw8u9UMyMzNTeXl5lV7TpXD06FEtW7ZM06ZNc7n+tttu09KlS5Wfn6/AwEBH+/z58xUUFKRrrrlGx48fLzWuUaNGToFo4MCBatq0qV588UWX4aZLly668847Ha+vvfZaPfLII3rttdf01FNPXfAY9u3bp7vvvltNmjTR6tWr1aBBA8e6YcOGaffu3Vq2bNkFt3G5KikpUVFRkby9vd3yuXClVatWatOmjebMmUO4sTBuS+GyMW/ePNWpU0e9evXSnXfeqXnz5l2w/4svvqgmTZqoRo0aiomJ0datWy+6j9mzZ+uWW25R/fr1ZbfbFRYWpqlTpzr1CQ0N1bZt2/Txxx87bld07dpV0vnn3CxatEjh4eGqUaOGAgMDdd999+n777936jNw4ED5+vrq+++/V79+/eTr66t69erpiSeeUHFx8QXr3rdvn4wx6ty5c6l1NptN9evXl/TLnJj+/ftLkm6++WZH/efqPd+8iNDQ0FJXqbZt26ZbbrlFNWrUUOPGjTVu3DiVlJQ49UlMTFRgYKB++umnUtvs0aOHrr322gse17Jly/Tzzz8rNjbW5fq+ffvKbrdr0aJFTu3z58/XXXfdJU9Pzwtu/5x69eqpZcuW2rNnT5n6d+nSRZLK1P+FF17Q6dOnNXPmTKdgc07z5s01fPhwx+uff/5ZzzzzjJo1aya73a7Q0FA9/fTTKiwsdBoXGhqq22+/XdnZ2YqIiFCNGjXUtm1bx9/l4sWL1bZtW3l7eys8PFxfffWV0/hz59vevXsVFxcnHx8fNWzYUGPHjpUxxqnvhAkT1KlTJwUEBKhGjRoKDw/Xm2++WepYbDabkpOTNW/ePLVu3Vp2u10rVqxwrPv1uXXq1Ck99thjCg0Nld1uV/369dW9e3dt3LjRaZsV8dnp3r273n333VLHCesg3OCyMW/ePP35z3+Wl5eXBgwYoF27dumLL75w2fe1117TSy+9pGHDhik1NVVbt27VLbfcotzc3AvuY+rUqWrSpImefvppTZw4USEhIRo6dKimTJni6JOZmanGjRurZcuWmjt3rubOnau//e1v593mnDlzHD9o09PTNXjwYC1evFg33nijTpw44dS3uLhYcXFxCggI0IQJExQTE6OJEyde9JZFkyZNJP3yg+DHH388b7+bbrpJjz76qCTp6aefdtTfqlWrC27/t3JycnTzzTdr06ZN+utf/6rHHntMr732miZNmuTU7/7779exY8e0cuXKUuNXr15d6nbSb61Zs0YBAQGO4/utmjVrqm/fvnrjjTccbV9//bW2bdume+65p8zH8/PPP+u7775TnTp1ytT/3HylsvR/99131bRpU3Xq1KlM2x40aJBGjRql66+/Xi+++KJiYmKUnp6uu+++u1Tf3bt365577lHv3r2Vnp6u48ePq3fv3po3b55GjBih++67T2PGjNGePXt01113lQqfxcXF6tmzp4KCgvTCCy8oPDxcaWlppa6ITpo0SR06dNDYsWP17LPPqlq1aurfv7/LK06rV6/WiBEjFB8fr0mTJp331ueQIUM0depU3XHHHXrllVf0xBNPqEaNGk5zmSrqsxMeHq4TJ05o27Zt5/trwOXOAJeBL7/80kgyq1atMsYYU1JSYho3bmyGDx/u1G/fvn1GkqlRo4b57rvvHO3r1q0zksyIESMcbWlpaea3H4Eff/yx1L7j4uJM06ZNndpat25tYmJiSvX96KOPjCTz0UcfGWOMKSoqMvXr1zdt2rQxZ8+edfR77733jCQzatQoR1tiYqKRZMaOHeu0zQ4dOpjw8HAX74qzhIQEI8nUqVPH/OlPfzITJkww27dvL9Vv0aJFTjX+miSTlpZWqr1JkyYmMTHR8fqxxx4zksy6descbUePHjX+/v5Gktm3b58xxpji4mLTuHFjEx8f77S9jIwMY7PZzN69ey94TDfeeKPLYz/3Pi9atMi89957xmazmYMHDxpjjHnyyScdf18xMTGmdevWpY6lR48eJi8vz+Tl5ZktW7aY+++/30gyw4YNc7mfWbNmmby8PHP48GGzYsUK07x5c2Oz2cz69esvWH9BQYGRZPr27XvBfuds2rTJSDKDBg1yan/iiSeMJLN69Wqn45Bk1qxZ42hbuXKl4/w/cOCAo/2f//xnqb/zc+fbX/7yF0dbSUmJ6dWrl/Hy8jJ5eXmO9t9+LoqKikybNm3MLbfc4tQuyXh4eJht27aVOrbfnlv+/v6l3u/f7qOiPjtr1qwxkszChQvPu39c3rhyg8vCvHnzFBQUpJtvvlnSL5e44+PjtWDBApeXnfv166dGjRo5XkdGRioqKuqij4DWqFHD8eeCggLl5+crJiZGe/fuVUFBQbnr/vLLL3X06FENHTrUac5Br1691LJlS5f/8x0yZIjT6y5dumjv3r0X3dfs2bP18ssv6+qrr9bbb7+tJ554Qq1atVK3bt1KXcb/o5YvX66OHTsqMjLS0VavXj3de++9Tv08PDx07733aunSpTp16pSjfd68eerUqZOuvvrqC+7n2LFjF7060qNHD9WtW1cLFiyQMUYLFizQgAEDLjjmgw8+UL169VSvXj21bdtWc+fOVVJSksaPH++y/wMPPKB69eqpYcOG6tmzpwoKCjR37lzdcMMNF9zPyZMnJUm1atW6YL9zzp2fKSkpTu3nJj//9nwJCwtTdHS04/W5pwhvueUWXXXVVaXaXZ1HycnJjj+fu61UVFSkDz/80NH+68/F8ePHVVBQoC5dupS6hSRJMTExCgsLu8iRSrVr19a6det0+PBhl+sr8rNz7pzKz8+/aJ24PBFuUOUVFxdrwYIFuvnmm7Vv3z7t3r1bu3fvVlRUlHJzc5WVlVVqzDXXXFOqrUWLFhd9/Pmzzz5TbGysfHx8VLt2bdWrV09PP/20JP2ucHPgwAFJcjm3pGXLlo7153h7e6tevXpObXXq1HE5Kfa3PDw8NGzYMG3YsEH5+fl65513dOutt2r16tUub2n8EQcOHHD5Hrs6zoSEBJ09e1Zvv/22JGnHjh3asGGD7r///jLty1xkXkT16tXVv39/zZ8/X5988okOHTp00VtSUVFRWrVqlVasWKEJEyaodu3aOn78+Hmfchs1apRWrVqlt99+WwkJCSooKJCHx8X/+fTz85Mkp2B3IQcOHJCHh0epJ8OCg4NVu3btUufLrwOMJPn7+0uSQkJCXLb/9jzy8PBQ06ZNndpatGghSU6flffee08dO3aUt7e36tatq3r16mnq1KkuPxMXC6znvPDCC9q6datCQkIUGRmp0aNHOwWRivzsnDunLvX3XKHqINygylu9erWOHDmiBQsW6JprrnEsd911lyRddGJxWe3Zs0fdunVTfn6+MjIytGzZMq1atUojRoyQpFLzFSpCWSfAXkxAQID69Omj5cuXKyYmRp9++mmpHwblcbEJzRcSFham8PBwx/fRvP766/Ly8nL8/V1IQEBAmYLdPffco02bNmn06NFq167dRa8cBAYGKjY2VnFxcXr88cf1+uuva8mSJaXmDJ3Ttm1bxcbGql+/fnr11VfVp08fDR48WIcOHbrgfvz8/NSwYcMyTWb/tbL+0D3f+XK+9osFRVf+85//qE+fPvL29tYrr7yi5cuXa9WqVbrnnntcbu/XV3ku5K677tLevXs1efJkNWzYUOPHj1fr1q31/vvvl7tGqXyfnXPn1K+fsIO1EG5Q5c2bN0/169fXokWLSi0DBgzQ22+/XepL0Hbt2lVqOzt37rzg97q8++67Kiws1NKlS/Xwww/rtttuU2xsrMt/rMv6w+fcRNgdO3aUWrdjx47zTpS9lCIiIiT98n0u0oVrr1OnTqmJmkVFRY6x5zRp0sTle+zqOKVfrt6cC6nz589Xr169yjQZt2XLltq3b99F+91444266qqrlJ2dXa6JxOf06tVLMTExevbZZ3XmzJmL9n/uuef03//+V//4xz8u2vf222/Xnj17tHbt2ov2bdKkiUpKSkq9t7m5uTpx4sQlP19KSkpK3bbZuXOnJDk+K2+99Za8vb21cuVKPfDAA7r11lvP+/RaeTVo0EBDhw7VkiVLtG/fPgUEBDje04r87Jw7p8o7kR6XD8INqrSzZ89q8eLFuv3223XnnXeWWpKTk3Xq1CktXbrUadySJUuc5pmsX79e69at06233nrefZ37n9+v/zdaUFCg2bNnl+rr4+NTKgS4EhERofr162vatGlOj/K+//772r59u3r16nXRbZRFTk6Ovvnmm1LtRUVFysrKcrrV4ePjI0ku62/WrJk++eQTp7bp06eXunJz22236fPPP9f69esdbXl5eee9ijZgwADZbDYNHz5ce/fuvehTUudER0fr+PHjF51zZLPZ9NJLLyktLa3Mt7t+a+TIkTp27JhmzJhx0b7NmjXTHXfcoTlz5ignJ+eCfZ966in5+Pho0KBBLp/W27Nnj+OK0W233Sbplyfyfi0jI0OSLtn58msvv/yy48/GGL388suqXr26unXrJumXz4XNZnM6B/bv368lS5b87n0WFxeXuqVVv359NWzY0PE5qcjPzoYNG+Tv76/WrVv/7m2gauNL/FClnZuI2qdPH5frO3bsqHr16mnevHmKj493tDdv3lw33nijHnnkERUWFiozM1MBAQEX/MK1Hj16yMvLS71799bDDz+s06dPa8aMGapfv36pKxfh4eGaOnWqxo0bp+bNm6t+/fouvxCsevXqev7555WUlKSYmBgNGDBAubm5jkdkz93y+qO+++47RUZG6pZbblG3bt0UHByso0eP6o033tDXX3+txx57zHEJvn379vL09NTzzz+vgoIC2e12x3f7DBo0SEOGDNEdd9yh7t276+uvv9bKlStLXb5/6qmnNHfuXPXs2VPDhw+Xj4+Ppk+friZNmmjz5s2l6qtXr5569uypRYsWqXbt2mX+wdSrVy9Vq1ZNH374oR566KEL9u3bt6/69u1bxnestFtvvVVt2rRRRkaGhg0bpurVq1+w/5NPPql///vfyszM1HPPPXfefs2aNdP8+fMVHx+vVq1aOX1D8Zo1a7Ro0SLHdwi1a9dOiYmJmj59uk6cOKGYmBitX79er776qvr16+eYUH+peHt7a8WKFUpMTFRUVJTef/99LVu2TE8//bRj/kqvXr2UkZGhnj176p577tHRo0c1ZcoUNW/e3OXfdVmcOnVKjRs31p133ql27drJ19dXH374ob744gtNnDhRUsV+dlatWqXevXsz58bK3PikFnBRvXv3Nt7e3ubMmTPn7TNw4EBTvXp1k5+f73gUfPz48WbixIkmJCTE2O1206VLF/P11187jXP1KPjSpUvNddddZ7y9vU1oaKh5/vnnzaxZs5webzbGmJycHNOrVy9Tq1YtI8nxWPhvHwU/Z+HChaZDhw7GbrebunXrmnvvvdfpUXVjfnmc1cfHp9Txuarzt06ePGkmTZpk4uLiTOPGjU316tVNrVq1THR0tJkxY4YpKSlx6j9jxgzTtGlT4+np6VRvcXGxGTlypAkMDDQ1a9Y0cXFxZvfu3aUeBTfGmM2bN5uYmBjj7e1tGjVqZJ555hkzc+bMUu/VOf/+97+NJPPQQw9d8Fh+q0+fPqZbt25Obb9+FPxCzvcoeK9evVz2nzNnjpFkZs+eXab9dO3a1fj5+ZkTJ05c9Dh27txpBg8ebEJDQ42Xl5epVauW6dy5s5k8ebL573//6+j3008/mTFjxpirr77aVK9e3YSEhJjU1FSnPhc6Drl4pP3Xn4tzzp1ve/bsMT169DA1a9Y0QUFBJi0tzRQXFzuNnzlzprnmmmuM3W43LVu2NLNnz3Z5Xrra96/XnXsUvLCw0Dz55JOmXbt2platWsbHx8e0a9fOvPLKK6XGXerPzvbt240k8+GHH7qsE9ZgM4avaARQ8d555x3169dPn3zyieMbfsviP//5j7p27apvv/3W5RNa+H0GDhyoN998U6dPn3Z3KZXqscce0yeffKINGzZw5cbCmHMDoFLMmDFDTZs21Y033liucV26dFGPHj30wgsvVFBluFIcO3ZM//rXvzRu3DiCjcUx5wZAhVqwYIE2b96sZcuWadKkSb/rh8rvfTwY+LWAgIAr7krVlYpwA6BCDRgwQL6+vnrwwQc1dOhQd5cD4ArAnBsAAGApzLkBAACWQrgBAACWcsXNuSkpKdHhw4dVq1YtZssDAHCZMMbo1KlTatiw4UV/ce0VF24OHz5c6jfmAgCAy8OhQ4fUuHHjC/a54sJNrVq1JP3y5vj5+bm5GgAAUBYnT55USEiI4+f4hVxx4ebcrSg/Pz/CDQAAl5myTClhQjEAALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALCUau4uAABgLaF/XebuEuBm+5/r5db9c+UGAABYCuEGAABYCuEGAABYCnNuLjHuNcPd95oB4ErHlRsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGApVSLcTJkyRaGhofL29lZUVJTWr19/3r5du3aVzWYrtfTq1asSKwYAAFWV28PNwoULlZKSorS0NG3cuFHt2rVTXFycjh496rL/4sWLdeTIEceydetWeXp6qn///pVcOQAAqIrcHm4yMjI0ePBgJSUlKSwsTNOmTVPNmjU1a9Ysl/3r1q2r4OBgx7Jq1SrVrFmTcAMAACS5OdwUFRVpw4YNio2NdbR5eHgoNjZWa9euLdM2Zs6cqbvvvls+Pj4u1xcWFurkyZNOCwAAsC63hpv8/HwVFxcrKCjIqT0oKEg5OTkXHb9+/Xpt3bpVgwYNOm+f9PR0+fv7O5aQkJA/XDcAAKi6qrm7gD9i5syZatu2rSIjI8/bJzU1VSkpKY7XJ0+eJODA0kL/uszdJcDN9j/HAxa4srk13AQGBsrT01O5ublO7bm5uQoODr7g2DNnzmjBggUaO3bsBfvZ7XbZ7fY/XCsAALg8uPW2lJeXl8LDw5WVleVoKykpUVZWlqKjoy84dtGiRSosLNR9991X0WUCAIDLiNtvS6WkpCgxMVERERGKjIxUZmamzpw5o6SkJElSQkKCGjVqpPT0dKdxM2fOVL9+/RQQEOCOsgEAQBXl9nATHx+vvLw8jRo1Sjk5OWrfvr1WrFjhmGR88OBBeXg4X2DasWOHPv30U33wwQfuKBkAAFRhbg83kpScnKzk5GSX67Kzs0u1XXvttTLGVHBVAADgcuT2L/EDAAC4lAg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUtwebqZMmaLQ0FB5e3srKipK69evv2D/EydOaNiwYWrQoIHsdrtatGih5cuXV1K1AACgqqvmzp0vXLhQKSkpmjZtmqKiopSZmam4uDjt2LFD9evXL9W/qKhI3bt3V/369fXmm2+qUaNGOnDggGrXrl35xQMAgCrJreEmIyNDgwcPVlJSkiRp2rRpWrZsmWbNmqW//vWvpfrPmjVLP/zwg9asWaPq1atLkkJDQyuzZAAAUMW57bZUUVGRNmzYoNjY2P8V4+Gh2NhYrV271uWYpUuXKjo6WsOGDVNQUJDatGmjZ599VsXFxefdT2FhoU6ePOm0AAAA63JbuMnPz1dxcbGCgoKc2oOCgpSTk+NyzN69e/Xmm2+quLhYy5cv19///ndNnDhR48aNO+9+0tPT5e/v71hCQkIu6XEAAICqxe0TisujpKRE9evX1/Tp0xUeHq74+Hj97W9/07Rp0847JjU1VQUFBY7l0KFDlVgxAACobG6bcxMYGChPT0/l5uY6tefm5io4ONjlmAYNGqh69ery9PR0tLVq1Uo5OTkqKiqSl5dXqTF2u112u/3SFg8AAKost1258fLyUnh4uLKyshxtJSUlysrKUnR0tMsxnTt31u7du1VSUuJo27lzpxo0aOAy2AAAgCuPW29LpaSkaMaMGXr11Ve1fft2PfLIIzpz5ozj6amEhASlpqY6+j/yyCP64YcfNHz4cO3cuVPLli3Ts88+q2HDhrnrEAAAQBXj1kfB4+PjlZeXp1GjRiknJ0ft27fXihUrHJOMDx48KA+P/+WvkJAQrVy5UiNGjNB1112nRo0aafjw4Ro5cqS7DgEAAFQxbg03kpScnKzk5GSX67Kzs0u1RUdH6/PPP6/gqgAAwOXqsnpaCgAA4GIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFIINwAAwFKqRLiZMmWKQkND5e3traioKK1fv/68fefMmSObzea0eHt7V2K1AACgKnN7uFm4cKFSUlKUlpamjRs3ql27doqLi9PRo0fPO8bPz09HjhxxLAcOHKjEigEAQFXm9nCTkZGhwYMHKykpSWFhYZo2bZpq1qypWbNmnXeMzWZTcHCwYwkKCqrEigEAQFXm1nBTVFSkDRs2KDY21tHm4eGh2NhYrV279rzjTp8+rSZNmigkJER9+/bVtm3bztu3sLBQJ0+edFoAAIB1uTXc5Ofnq7i4uNSVl6CgIOXk5Lgcc+2112rWrFl655139Prrr6ukpESdOnXSd99957J/enq6/P39HUtISMglPw4AAFB1uP22VHlFR0crISFB7du3V0xMjBYvXqx69erpn//8p8v+qampKigocCyHDh2q5IoBAEBlqubOnQcGBsrT01O5ublO7bm5uQoODi7TNqpXr64OHTpo9+7dLtfb7XbZ7fY/XCsAALg8uPXKjZeXl8LDw5WVleVoKykpUVZWlqKjo8u0jeLiYm3ZskUNGjSoqDIBAMBlxK1XbiQpJSVFiYmJioiIUGRkpDIzM3XmzBklJSVJkhISEtSoUSOlp6dLksaOHauOHTuqefPmOnHihMaPH68DBw5o0KBB7jwMAABQRbg93MTHxysvL0+jRo1STk6O2rdvrxUrVjgmGR88eFAeHv+7wHT8+HENHjxYOTk5qlOnjsLDw7VmzRqFhYW56xAAAEAV4vZwI0nJyclKTk52uS47O9vp9YsvvqgXX3yxEqoCAACXo8vuaSkAAIALIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLuaTh5siRI0pOTr6UmwQAACiXauUdsG3bNn300Ufy8vLSXXfdpdq1ays/P1//+Mc/NG3aNDVt2rQi6gQAACiTcl25Wbp0qTp06KBHH31UQ4YMUUREhD766CO1atVK27dv19tvv61t27ZVVK0AAAAXVa5wM27cOA0bNkwnT55URkaG9u7dq0cffVTLly/XihUr1LNnz4qqEwAAoEzKFW527NihYcOGydfXV3/5y1/k4eGhF198UTfccENF1QcAAFAu5Qo3p06dkp+fnyTJ09NTNWrUYI4NAACoUso9oXjlypXy9/eXJJWUlCgrK0tbt2516tOnT59LUx0AAEA5lTvcJCYmOr1++OGHnV7bbDYVFxeXa5tTpkzR+PHjlZOTo3bt2mny5MmKjIy86LgFCxZowIAB6tu3r5YsWVKufQIAAGsq122pkpKSiy7lDTYLFy5USkqK0tLStHHjRrVr105xcXE6evToBcft379fTzzxhLp06VKu/QEAAGu75N9QfPbs2XL1z8jI0ODBg5WUlKSwsDBNmzZNNWvW1KxZs847pri4WPfee6/GjBlz0Tk/hYWFOnnypNMCAACs65KFm8LCQk2cOFFXX311mccUFRVpw4YNio2N/V9BHh6KjY3V2rVrzztu7Nixql+/vh588MGL7iM9PV3+/v6OJSQkpMz1AQCAy0+5wk1hYaFSU1MVERGhTp06Oea5zJ49W1dffbUyMzM1YsSIMm8vPz9fxcXFCgoKcmoPCgpSTk6OyzGffvqpZs6cqRkzZpRpH6mpqSooKHAshw4dKnN9AADg8lOuCcWjRo3SP//5T8XGxmrNmjXq37+/kpKS9PnnnysjI0P9+/eXp6dnRdWqU6dO6f7779eMGTMUGBhYpjF2u112u73CagIAAFVLucLNokWL9Nprr6lPnz7aunWrrrvuOv3888/6+uuvZbPZyr3zwMBAeXp6Kjc316k9NzdXwcHBpfrv2bNH+/fvV+/evR1tJSUlvxxItWrasWOHmjVrVu46AACAdZTrttR3332n8PBwSVKbNm1kt9s1YsSI3xVsJMnLy0vh4eHKyspytJ377pzo6OhS/Vu2bKktW7Zo06ZNjqVPnz66+eabtWnTJubTAACA8l25KS4ulpeX1/8GV6smX1/fP1RASkqKEhMTFRERocjISGVmZurMmTNKSkqSJCUkJKhRo0ZKT0+Xt7e32rRp4zS+du3aklSqHQAAXJnKFW6MMRo4cKBjDst///tfDRkyRD4+Pk79Fi9eXOZtxsfHKy8vT6NGjVJOTo7at2+vFStWOCYZHzx4UB4el/yJdQAAYFHlCjcJCQlOt6Duu+++S1JEcnKykpOTXa7Lzs6+4Ng5c+ZckhoAAIA1lCvcECQAAEBVV65w88ADD1y0j81m08yZM393QQAAAH9Eua/cNGnSRB06dJAxpqJqAgAA+N3KFW4eeeQRvfHGG9q3b5+SkpJ03333qW7duhVVGwAAQLmV6zGkKVOm6MiRI3rqqaf07rvvKiQkRHfddZdWrlzJlRwAAFAllPsZa7vdrgEDBmjVqlX65ptv1Lp1aw0dOlShoaE6ffp0RdQIAABQZn/oC2Q8PDxks9lkjFFxcfGlqgkAAOB3K3e4KSws1BtvvKHu3burRYsW2rJli15++WUdPHjwD39bMQAAwB9VrgnFQ4cO1YIFCxQSEqIHHnhAb7zxRpl/OzcAAEBlKFe4mTZtmq666io1bdpUH3/8sT7++GOX/crz6xcAAAAupT/06xcAAACqGn79AgAAsBR+3TYAALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALCUKhFupkyZotDQUHl7eysqKkrr168/b9/FixcrIiJCtWvXlo+Pj9q3b6+5c+dWYrUAAKAqc3u4WbhwoVJSUpSWlqaNGzeqXbt2iouL09GjR132r1u3rv72t79p7dq12rx5s5KSkpSUlKSVK1dWcuUAAKAqcnu4ycjI0ODBg5WUlKSwsDBNmzZNNWvW1KxZs1z279q1q/70pz+pVatWatasmYYPH67rrrtOn376aSVXDgAAqiK3hpuioiJt2LBBsbGxjjYPDw/FxsZq7dq1Fx1vjFFWVpZ27Nihm266yWWfwsJCnTx50mkBAADW5dZwk5+fr+LiYgUFBTm1BwUFKScn57zjCgoK5OvrKy8vL/Xq1UuTJ09W9+7dXfZNT0+Xv7+/YwkJCbmkxwAAAKoWt9+W+j1q1aqlTZs26YsvvtA//vEPpaSkKDs722Xf1NRUFRQUOJZDhw5VbrEAAKBSVXPnzgMDA+Xp6anc3Fyn9tzcXAUHB593nIeHh5o3by5Jat++vbZv36709HR17dq1VF+73S673X5J6wYAAFWXW6/ceHl5KTw8XFlZWY62kpISZWVlKTo6uszbKSkpUWFhYUWUCAAALjNuvXIjSSkpKUpMTFRERIQiIyOVmZmpM2fOKCkpSZKUkJCgRo0aKT09XdIvc2giIiLUrFkzFRYWavny5Zo7d66mTp3qzsMAAABVhNvDTXx8vPLy8jRq1Cjl5OSoffv2WrFihWOS8cGDB+Xh8b8LTGfOnNHQoUP13XffqUaNGmrZsqVef/11xcfHu+sQAABAFeL2cCNJycnJSk5OdrnutxOFx40bp3HjxlVCVQAA4HJ0WT4tBQAAcD6EGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYClVItxMmTJFoaGh8vb2VlRUlNavX3/evjNmzFCXLl1Up04d1alTR7GxsRfsDwAArixuDzcLFy5USkqK0tLStHHjRrVr105xcXE6evSoy/7Z2dkaMGCAPvroI61du1YhISHq0aOHvv/++0quHAAAVEVuDzcZGRkaPHiwkpKSFBYWpmnTpqlmzZqaNWuWy/7z5s3T0KFD1b59e7Vs2VL/+te/VFJSoqysLJf9CwsLdfLkSacFAABYl1vDTVFRkTZs2KDY2FhHm4eHh2JjY7V27doybePHH3/UTz/9pLp167pcn56eLn9/f8cSEhJySWoHAABVk1vDTX5+voqLixUUFOTUHhQUpJycnDJtY+TIkWrYsKFTQPq11NRUFRQUOJZDhw794boBAEDVVc3dBfwRzz33nBYsWKDs7Gx5e3u77GO322W32yu5MgAA4C5uDTeBgYHy9PRUbm6uU3tubq6Cg4MvOHbChAl67rnn9OGHH+q6666ryDIBAMBlxK23pby8vBQeHu40Gfjc5ODo6OjzjnvhhRf0zDPPaMWKFYqIiKiMUgEAwGXC7belUlJSlJiYqIiICEVGRiozM1NnzpxRUlKSJCkhIUGNGjVSenq6JOn555/XqFGjNH/+fIWGhjrm5vj6+srX19dtxwEAAKoGt4eb+Ph45eXladSoUcrJyVH79u21YsUKxyTjgwcPysPjfxeYpk6dqqKiIt15551O20lLS9Po0aMrs3QAAFAFuT3cSFJycrKSk5NdrsvOznZ6vX///oovCAAAXLbc/iV+AAAAlxLhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWIrbw82UKVMUGhoqb29vRUVFaf369eftu23bNt1xxx0KDQ2VzWZTZmZm5RUKAAAuC24NNwsXLlRKSorS0tK0ceNGtWvXTnFxcTp69KjL/j/++KOaNm2q5557TsHBwZVcLQAAuBy4NdxkZGRo8ODBSkpKUlhYmKZNm6aaNWtq1qxZLvvfcMMNGj9+vO6++27Z7fZKrhYAAFwO3BZuioqKtGHDBsXGxv6vGA8PxcbGau3atZdsP4WFhTp58qTTAgAArMtt4SY/P1/FxcUKCgpyag8KClJOTs4l2096err8/f0dS0hIyCXbNgAAqHrcPqG4oqWmpqqgoMCxHDp0yN0lAQCAClTNXTsODAyUp6encnNzndpzc3Mv6WRhu93O/BwAAK4gbrty4+XlpfDwcGVlZTnaSkpKlJWVpejoaHeVBQAALnNuu3IjSSkpKUpMTFRERIQiIyOVmZmpM2fOKCkpSZKUkJCgRo0aKT09XdIvk5C/+eYbx5+///57bdq0Sb6+vmrevLnbjgMAAFQdbg038fHxysvL06hRo5STk6P27dtrxYoVjknGBw8elIfH/y4uHT58WB06dHC8njBhgiZMmKCYmBhlZ2dXdvkAAKAKcmu4kaTk5GQlJye7XPfbwBIaGipjTCVUBQAALleWf1oKAABcWQg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUqpEuJkyZYpCQ0Pl7e2tqKgorV+//oL9Fy1apJYtW8rb21tt27bV8uXLK6lSAABQ1bk93CxcuFApKSlKS0vTxo0b1a5dO8XFxeno0aMu+69Zs0YDBgzQgw8+qK+++kr9+vVTv379tHXr1kquHAAAVEVuDzcZGRkaPHiwkpKSFBYWpmnTpqlmzZqaNWuWy/6TJk1Sz5499eSTT6pVq1Z65plndP311+vll1+u5MoBAEBVVM2dOy8qKtKGDRuUmprqaPPw8FBsbKzWrl3rcszatWuVkpLi1BYXF6clS5a47F9YWKjCwkLH64KCAknSyZMn/2D1rpUU/lgh28Xlo6LOrbLiHATnINytIs7Bc9s0xly0r1vDTX5+voqLixUUFOTUHhQUpG+//dblmJycHJf9c3JyXPZPT0/XmDFjSrWHhIT8zqqBC/PPdHcFuNJxDsLdKvIcPHXqlPz9/S/Yx63hpjKkpqY6XekpKSnRDz/8oICAANlsNjdWZj0nT55USEiIDh06JD8/P3eXgysQ5yDcjXOw4hhjdOrUKTVs2PCifd0abgIDA+Xp6anc3Fyn9tzcXAUHB7scExwcXK7+drtddrvdqa127dq/v2hclJ+fHx9quBXnINyNc7BiXOyKzTlunVDs5eWl8PBwZWVlOdpKSkqUlZWl6Ohol2Oio6Od+kvSqlWrztsfAABcWdx+WyolJUWJiYmKiIhQZGSkMjMzdebMGSUlJUmSEhIS1KhRI6Wnp0uShg8frpiYGE2cOFG9evXSggUL9OWXX2r69OnuPAwAAFBFuD3cxMfHKy8vT6NGjVJOTo7at2+vFStWOCYNHzx4UB4e/7vA1KlTJ82fP1//93//p6efflrXXHONlixZojZt2rjrEPD/2e12paWllboNCFQWzkG4G+dg1WAzZXmmCgAA4DLh9i/xAwAAuJQINwAAwFIINwAAwFIINwAAwFIIN3Cpa9eueuyxx9xdBgBUqD/6b93vHb9//37ZbDZt2rTpvH2ys7Nls9l04sSJ313flcrtj4IDAHClCQkJ0ZEjRxQYGOjuUiyJKzcArhg//fSTu0sAVFRUJE9PTwUHB6taNa4xVATCDXTmzBklJCTI19dXDRo00MSJE53WFxYW6oknnlCjRo3k4+OjqKgoZWdnO9bPmTNHtWvX1sqVK9WqVSv5+vqqZ8+eOnLkiKNPdna2IiMj5ePjo9q1a6tz5846cOCAY/0777yj66+/Xt7e3mratKnGjBmjn3/+ucKPHe715ptvqm3btqpRo4YCAgIUGxurM2fOaODAgerXr5/GjBmjevXqyc/PT0OGDFFRUZFj7IoVK3TjjTeqdu3aCggI0O233649e/Y41p+77L9w4ULFxMTI29tb8+bN04EDB9S7d2/VqVNHPj4+at26tZYvX+4Yt3XrVt16663y9fVVUFCQ7r//fuXn51fq+4LKVVJSoqeeekp169ZVcHCwRo8eLUl64IEHdPvttzv1/emnn1S/fn3NnDnT0fbzzz8rOTlZ/v7+CgwM1N///nf9+ivkQkND9cwzzyghIUF+fn566KGHXN6WWr58uVq0aKEaNWro5ptv1v79+yvysK3N4Ir3yCOPmKuuusp8+OGHZvPmzeb22283tWrVMsOHDzfGGDNo0CDTqVMn88knn5jdu3eb8ePHG7vdbnbu3GmMMWb27NmmevXqJjY21nzxxRdmw4YNplWrVuaee+4xxhjz008/GX9/f/PEE0+Y3bt3m2+++cbMmTPHHDhwwBhjzCeffGL8/PzMnDlzzJ49e8wHH3xgQkNDzejRo93yfqByHD582FSrVs1kZGSYffv2mc2bN5spU6aYU6dOmcTEROPr62vi4+PN1q1bzXvvvWfq1atnnn76acf4N99807z11ltm165d5quvvjK9e/c2bdu2NcXFxcYYY/bt22ckmdDQUPPWW2+ZvXv3msOHD5tevXqZ7t27m82bN5s9e/aYd99913z88cfGGGOOHz9u6tWrZ1JTU8327dvNxo0bTffu3c3NN9/slvcIFS8mJsb4+fmZ0aNHm507d5pXX33V2Gw288EHH5jPPvvMeHp6msOHDzv6L1682Pj4+JhTp045xvv6+prhw4ebb7/91rz++uumZs2aZvr06Y4xTZo0MX5+fmbChAlm9+7dZvfu3Y7z86uvvjLGGHPw4EFjt9tNSkqKYztBQUFGkjl+/HhlviWWQLi5wp06dcp4eXmZf//73462Y8eOmRo1apjhw4ebAwcOGE9PT/P99987jevWrZtJTU01xvwSbiSZ3bt3O9ZPmTLFBAUFObYnyWRnZ7usoVu3bubZZ591aps7d65p0KDBJTlGVE0bNmwwksz+/ftLrUtMTDR169Y1Z86ccbRNnTrV+Pr6OsLLb+Xl5RlJZsuWLcaY/4WbzMxMp35t27Y9b3B+5plnTI8ePZzaDh06ZCSZHTt2lOv4cHmIiYkxN954o1PbDTfcYEaOHGmMMSYsLMw8//zzjnW9e/c2AwcOdBrfqlUrU1JS4mgbOXKkadWqleN1kyZNTL9+/Zz28dtwk5qaasLCwpz6jBw5knDzO3Fb6gq3Z88eFRUVKSoqytFWt25dXXvttZKkLVu2qLi4WC1atJCvr69j+fjjj51uAdSsWVPNmjVzvG7QoIGOHj3q2N7AgQMVFxen3r17a9KkSU63rL7++muNHTvWafuDBw/WkSNH9OOPP1b0WwA3adeunbp166a2bduqf//+mjFjho4fP+60vmbNmo7X0dHROn36tA4dOiRJ2rVrlwYMGKCmTZvKz89PoaGhkn75fXS/FhER4fT60Ucf1bhx49S5c2elpaVp8+bNjnVff/21PvroI6dzsWXLlpLkdL7DWq677jqn17/+92vQoEGaPXu2JCk3N1fvv/++HnjgAaf+HTt2lM1mc7yOjo7Wrl27VFxc7Gj77Xn4W9u3b3f6d/jcdvD7EG5wQadPn5anp6c2bNigTZs2OZbt27dr0qRJjn7Vq1d3Gmez2ZzuOc+ePVtr165Vp06dtHDhQrVo0UKff/65Yx9jxoxx2v6WLVu0a9cueXt7V86BotJ5enpq1apVev/99xUWFqbJkyfr2muv1b59+8o0vnfv3vrhhx80Y8YMrVu3TuvWrZMkp3k5kuTj4+P0etCgQdq7d6/uv/9+bdmyRREREZo8ebKkX87F3r17O52LmzZt0q5du3TTTTddgqNGVeTq36+SkhJJUkJCgvbu3au1a9fq9ddf19VXX60uXbqUex+/PQ9RsZimfYVr1qyZqlevrnXr1umqq66SJB0/flw7d+5UTEyMOnTooOLiYh09evR3faB/rUOHDurQoYNSU1MVHR2t+fPnq2PHjrr++uu1Y8cONW/e/FIcEi4jNptNnTt3VufOnTVq1Cg1adJEb7/9tqRfrqKcPXtWNWrUkCR9/vnn8vX1VUhIiI4dO6YdO3ZoxowZjvPy008/LfN+Q0JCNGTIEA0ZMkSpqamaMWOG/vKXv+j666/XW2+9pdDQUJ5igSQpICBA/fr1c/wHLSkpqVSfc8H6nM8//1zXXHONPD09y7yfVq1aaenSpaW2g9+HKzdXOF9fXz344IN68skntXr1am3dulUDBw6Uh8cvp0aLFi107733KiEhQYsXL9a+ffu0fv16paena9myZWXax759+5Samqq1a9fqwIED+uCDD7Rr1y61atVKkjRq1Ci99tprGjNmjLZt26bt27drwYIF+r//+78KO26437p16/Tss8/qyy+/1MGDB7V48WLl5eU5zouioiI9+OCD+uabb7R8+XKlpaUpOTlZHh4eqlOnjgICAjR9+nTt3r1bq1evVkpKSpn2+9hjj2nlypXat2+fNm7cqI8++sixz2HDhumHH37QgAED9MUXX2jPnj1auXKlkpKSnG4x4MoyaNAgvfrqq9q+fbsSExNLrT948KBSUlK0Y8cOvfHGG5o8ebKGDx9ern0MGTJEu3bt0pNPPqkdO3Zo/vz5mjNnziU6gisP/zWBxo8f77gcX6tWLT3++OMqKChwrJ89e7bGjRunxx9/XN9//70CAwPVsWPHUo9Ink/NmjX17bff6tVXX9WxY8fUoEEDDRs2TA8//LAkKS4uTu+9957Gjh2r559/XtWrV1fLli01aNCgCjleVA1+fn765JNPlJmZqZMnT6pJkyaaOHGibr31Vi1cuFDdunXTNddco5tuukmFhYUaMGCA4xFdDw8PLViwQI8++qjatGmja6+9Vi+99JK6du160f0WFxdr2LBh+u677+Tn56eePXvqxRdflCQ1bNhQn332mUaOHKkePXqosLBQTZo0Uc+ePR2BH1ee2NhYNWjQQK1bt1bDhg1LrU9ISNDZs2cVGRkpT09PDR8+XA899FC59nHVVVfprbfe0ogRIzR58mRFRkbq2WefLTW/B2VjM7+eGAEAVcDAgQN14sQJLVmyxN2lADp9+rQaNWqk2bNn689//rO7y0EZcOUGAAAXSkpKlJ+fr4kTJ6p27drq06ePu0tCGRFuAABw4eDBg7r66qvVuHFjzZkzh0nmlxFuSwEAAEthhhwAALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALCU/wcwk0rf5rxx0QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Analysis (Automatic Categorization)"
      ],
      "metadata": {
        "id": "jld3THTXypND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def categorize_error(row):\n",
        "    if row[\"MRR\"] == 0:\n",
        "        return \"Retrieval Failure\"\n",
        "    if row[\"Faithfulness\"] < 0.4:\n",
        "        return \"Hallucination\"\n",
        "    return \"Correct\"\n",
        "\n",
        "results_df[\"Error_Type\"] = results_df.apply(categorize_error, axis=1)\n",
        "\n",
        "error_counts = Counter(results_df[\"Error_Type\"])\n",
        "error_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kHOdSLIzyqAT",
        "outputId": "36c21e20-f4ba-4b11-cd4f-a400e7885c2d"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Retrieval Failure': 1, 'Correct': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Distribution Plot"
      ],
      "metadata": {
        "id": "H4-rh4N3ytHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.bar(error_counts.keys(), error_counts.values())\n",
        "plt.title(\"Error Type Distribution\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.savefig(f\"{REPORT_DIR}/error_distribution.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "_Qh0rZ2Tyslt",
        "outputId": "9cd62e10-cb71-47cc-afdb-3adcd33b3ea2"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Failure Examples (For the sake of report i have kept this)"
      ],
      "metadata": {
        "id": "XO8sa6WEyw95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "failure_examples = results_df[\n",
        "    results_df[\"Error_Type\"] != \"Correct\"\n",
        "].head(5)\n",
        "\n",
        "failure_examples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "HhdAHahyyzI8",
        "outputId": "9def3dd5-049b-4577-847e-21d7395fa130"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Error_Type'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Error_Type'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-614714324.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m failure_examples = results_df[\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Error_Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Correct\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m ].head(5)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfailure_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Error_Type'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to save\n",
        "failure_examples.to_csv(\n",
        "    f\"{REPORT_DIR}/failure_examples.csv\",\n",
        "    index=False\n",
        ")"
      ],
      "metadata": {
        "id": "69cbsNNPy2Ef"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric Justification Text (AUTO-GENERATED)"
      ],
      "metadata": {
        "id": "OOFCBGsozJzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric_justification = {\n",
        "    \"Recall@K\": {\n",
        "        \"Why\": \"Measures whether the correct document is retrieved at all.\",\n",
        "        \"Method\": \"Checks if ground-truth URL appears in top-K retrieved URLs.\",\n",
        "        \"Interpretation\": \"Higher values indicate better retrieval coverage.\"\n",
        "    },\n",
        "    \"Faithfulness\": {\n",
        "        \"Why\": \"Detects hallucination risk in generated answers.\",\n",
        "        \"Method\": \"Computes lexical overlap between answer and retrieved context.\",\n",
        "        \"Interpretation\": \"Higher values indicate stronger grounding.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "metric_justification\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "p3pPgAxuzKvo",
        "outputId": "a659242e-dd28-483a-9e60-29fca7fbf57a"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Recall@K': {'Why': 'Measures whether the correct document is retrieved at all.',\n",
              "  'Method': 'Checks if ground-truth URL appears in top-K retrieved URLs.',\n",
              "  'Interpretation': 'Higher values indicate better retrieval coverage.'},\n",
              " 'Faithfulness': {'Why': 'Detects hallucination risk in generated answers.',\n",
              "  'Method': 'Computes lexical overlap between answer and retrieved context.',\n",
              "  'Interpretation': 'Higher values indicate stronger grounding.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Report Metadata (JSON)"
      ],
      "metadata": {
        "id": "xEe9KklEzRKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report_summary = {\n",
        "    \"overall_metrics\": metrics_summary,\n",
        "    \"ablation_results\": ablation_results,\n",
        "    \"error_analysis\": dict(error_counts),\n",
        "    \"files_generated\": os.listdir(REPORT_DIR)\n",
        "}\n",
        "\n",
        "with open(f\"{REPORT_DIR}/report_summary.json\", \"w\") as f:\n",
        "    json.dump(report_summary, f, indent=2)\n",
        "\n",
        "report_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WTihqbotzRp0",
        "outputId": "4e7ce6fb-2aec-4291-c632-350f7074f69b"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overall_metrics': {'MRR_URL': 0.7275,\n",
              "  'Recall@5': 0.86,\n",
              "  'Avg_Faithfulness': 0.9425,\n",
              "  'ablation': {'dense': 0.7499, 'sparse': 0.6987, 'hybrid': 0.7578}},\n",
              " 'ablation_results': {'dense': 0.7499, 'sparse': 0.6987, 'hybrid': 0.7578},\n",
              " 'error_analysis': {'Retrieval Failure': 1, 'Correct': 2},\n",
              " 'files_generated': ['results_table.csv',\n",
              "  'metrics_summary.png',\n",
              "  'mrr_distribution.png',\n",
              "  'faithfulness_distribution.png',\n",
              "  'ablation_mrr.png',\n",
              "  'error_distribution.png',\n",
              "  'failure_examples.csv',\n",
              "  'report_summary.json']}"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "4DbQ4aRaBPnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part A: Hybrid Retrieval-Augmented Generation (RAG) System\n",
        "\n",
        "In Part A, a complete Hybrid Retrieval-Augmented Generation (RAG) system was successfully designed and implemented using a combination of dense vector retrieval, sparse keyword-based retrieval, and Reciprocal Rank Fusion (RRF). Dense retrieval enabled semantic understanding of user queries through sentence embeddings and FAISS indexing, while sparse retrieval using BM25 ensured precise keyword matching and strong lexical coverage. By combining both approaches with RRF, the system effectively leveraged the strengths of each method, resulting in improved retrieval robustness and relevance.\n",
        "\n",
        "The retrieved evidence was integrated into a prompt and passed to an open-source large language model to generate grounded, context-aware responses. A user-friendly interface was built to allow interactive querying, display retrieved sources, and provide transparency into system behavior. Overall, Part A demonstrates a scalable and modular RAG architecture capable of producing accurate and explainable answers by balancing semantic and lexical retrieval signals.\n",
        "\n",
        "### Part A Summary Table\n",
        "\n",
        "| Component | Technique Used | Purpose |\n",
        "|--------|---------------|--------|\n",
        "| Dense Retrieval | Sentence Transformers + FAISS | Capture semantic similarity between query and documents |\n",
        "| Sparse Retrieval | BM25 | Preserve keyword precision and exact term matching |\n",
        "| Fusion Method | Reciprocal Rank Fusion (RRF) | Combine dense and sparse rankings robustly |\n",
        "| Generation | Open-source LLM | Generate context-grounded answers |\n",
        "| Interface | Gradio | Enable interactive querying and result inspection |\n",
        "\n",
        "---\n",
        "\n",
        "## Part B: Automated and Innovative Evaluation Framework\n",
        "\n",
        "Part B focused on building a comprehensive, automated evaluation framework to rigorously assess the Hybrid RAG system. A diverse set of questions was generated from the Wikipedia corpus, covering multiple question types such as factual, inferential, and multi-hop queries. Evaluation was conducted at the URL level to ensure that the system retrieves the correct source documents, not just relevant text fragments.\n",
        "\n",
        "The mandatory Mean Reciprocal Rank (MRR) metric measured how quickly the correct document appeared in the ranked results, while custom metrics such as Recall@K and Answer Faithfulness provided additional insights into retrieval coverage and answer grounding. To go beyond standard metrics, innovative evaluation techniques were introduced, including ablation studies comparing dense-only, sparse-only, and hybrid retrieval strategies, as well as automatic error analysis to categorize system failures.\n",
        "\n",
        "An automated pipeline was implemented to execute the entire evaluation process with a single command and generate structured outputs and visual reports. This ensured reproducibility, scalability, and clarity in performance analysis. Together, these evaluation strategies provide a holistic understanding of both retrieval effectiveness and generation reliability.\n",
        "\n",
        "### Part B Summary Table\n",
        "\n",
        "| Aspect | Approach | Key Insight |\n",
        "|------|---------|------------|\n",
        "| Question Generation | Automated corpus-based generation | Ensures diverse and scalable evaluation |\n",
        "| Mandatory Metric | MRR (URL-level) | Measures ranking quality of correct sources |\n",
        "| Custom Metrics | Recall@K, Faithfulness | Evaluate retrieval coverage and grounding |\n",
        "| Innovation | Ablation, Error Analysis | Reveal strengths and failure modes |\n",
        "| Automation | Single-command pipeline | Enables reproducible evaluation |\n",
        "\n",
        "---\n",
        "\n",
        "## Overall Takeaway\n",
        "\n",
        "This assignment demonstrates the end-to-end design of a Hybrid RAG system along with a rigorous and innovative evaluation framework.\n",
        "\n",
        "By combining complementary retrieval methods, applying principled fusion, and employing detailed evaluation techniques, the system achieves both strong performance and transparency.\n",
        "\n",
        "The modular design and automated analysis pipeline make the solution extensible to larger datasets and more advanced evaluation strategies, providing a solid foundation for real-world Retrieval-Augmented Generation systems.\n"
      ],
      "metadata": {
        "id": "m_QMLcS3BRnU"
      }
    }
  ]
}